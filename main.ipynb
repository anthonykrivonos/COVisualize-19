{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# COVisualize-19\n",
    "\n",
    "## [COMS 4771](http://www.cs.columbia.edu/~verma/classes/ml/index.html) Final Project\n",
    "\n",
    "Classifying COVID-19 patients from lung scans.\n",
    "\n",
    "Anthony Krivonos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "from os import mkdir, chdir\n",
    "from os.path import realpath, join, dirname, exists\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id           filename\n0      0    test/img-0.jpeg\n1      1    test/img-1.jpeg\n2      2    test/img-2.jpeg\n3      3    test/img-3.jpeg\n4      4    test/img-4.jpeg\n..   ...                ...\n479  479  test/img-479.jpeg\n480  480  test/img-480.jpeg\n481  481  test/img-481.jpeg\n482  482  test/img-482.jpeg\n483  483  test/img-483.jpeg\n\n[484 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>test/img-0.jpeg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>test/img-1.jpeg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>test/img-2.jpeg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>test/img-3.jpeg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>test/img-4.jpeg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>479</th>\n      <td>479</td>\n      <td>test/img-479.jpeg</td>\n    </tr>\n    <tr>\n      <th>480</th>\n      <td>480</td>\n      <td>test/img-480.jpeg</td>\n    </tr>\n    <tr>\n      <th>481</th>\n      <td>481</td>\n      <td>test/img-481.jpeg</td>\n    </tr>\n    <tr>\n      <th>482</th>\n      <td>482</td>\n      <td>test/img-482.jpeg</td>\n    </tr>\n    <tr>\n      <th>483</th>\n      <td>483</td>\n      <td>test/img-483.jpeg</td>\n    </tr>\n  </tbody>\n</table>\n<p>484 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 63
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Read CSVs into DataFrames.\n",
    "\"\"\"\n",
    "\n",
    "train_data = pd.read_csv('./train.csv')\n",
    "test_data = pd.read_csv('./test.csv')\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Quick Settings\n",
    "\n",
    "Keep these updated, so we only have to do certain tasks (like preprocessing) once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'PREPROCESS': False,\n 'PREPROCESS_METHOD_A': False,\n 'PREPROCESS_METHOD_B': False,\n 'PREPROCESS_METHOD_C': False,\n 'PREPROCESS_METHOD_D': False}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 64
    }
   ],
   "source": [
    "SETTINGS = {\n",
    "\n",
    "    # Preprocess the images at all?\n",
    "    \"PREPROCESS\": False,\n",
    "    \n",
    "    # Preprocess the images using specific methods\n",
    "    \"PREPROCESS_METHOD_A\": False,\n",
    "    \"PREPROCESS_METHOD_B\": False,\n",
    "    \"PREPROCESS_METHOD_C\": False,\n",
    "    \"PREPROCESS_METHOD_D\": False,\n",
    "    \n",
    "}\n",
    "\n",
    "SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Image Preprocessing\n",
    "\n",
    "#### Method A – Square images w/ padding\n",
    "\n",
    "1. Find smallest-dimension training image dimension. This will be the standard image size for both training and testing.\n",
    "2. Take this image's larger dimension and resize all images into squares with that side length. While doing this, center the images and pad the left and right sides.\n",
    "\n",
    "#### Method B – Crop images, ignoring aspect ratio\n",
    "\n",
    "1. Find smallest-dimension training image dimensions. This will be the standard image size for both training and testing.\n",
    "2. Resizeevery image to this height and width, ignoring the aspect ratio of each image.\n",
    "\n",
    "#### Method C – Crop images to smallest size, maintaining aspect ratio\n",
    "\n",
    "1. Find smallest-dimension training image dimensions. This will be the standard image size for both training and testing.\n",
    "2. Resize and crop every image to this height and width, maintaining the aspect ratio of each image and centering its source.\n",
    "\n",
    "#### Method D – Crop images to square, maintaining aspect ratio\n",
    "\n",
    "1. Find smallest-dimension training image dimension. This will be the standard image size for both training and testing.\n",
    "2. Resize and crop every image to this size, maintaining the aspect ratio of each image and centering its source.\n",
    "\n",
    "##### Tools\n",
    "- Uses OpenCV (`CV2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##\n",
    "#   Directory Names\n",
    "##\n",
    "\n",
    "# Name of the directory to put the processed images in\n",
    "PROCESSED_DIRECTORY = 'processed'\n",
    "\n",
    "# Different process method directories\n",
    "METHOD_A_DIRECTORY = 'method_a'\n",
    "METHOD_B_DIRECTORY = 'method_b'\n",
    "METHOD_C_DIRECTORY = 'method_c'\n",
    "METHOD_D_DIRECTORY = 'method_d'\n",
    "\n",
    "\n",
    "##\n",
    "#   Image Writing Helper Function\n",
    "##\n",
    "def relative_imwrite(relative_filepath, img):\n",
    "    \"\"\"\n",
    "    Call cv2.imwrite(..., img) on a relative file path.\n",
    "    :param relative_filepath: The path (i.e. 'processed/train/img-2.jpeg').\n",
    "    :param img: The cv2 image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Store current working directory so we can navigate back\n",
    "    cwd = os.getcwd()\n",
    "    \n",
    "    # Get index of last slash to use it as a splitting point\n",
    "    split_idx = relative_filepath.rindex(\"/\")\n",
    "    \n",
    "    # Create a relative path and filename from this\n",
    "    relative_path = relative_filepath[:split_idx]\n",
    "    file_name = relative_filepath[(split_idx + 1):]\n",
    "    \n",
    "    # Extract the directory names\n",
    "    directory_names = relative_path.split(\"/\")\n",
    "    top_directory_name = cwd\n",
    "    \n",
    "    # Create the directory if it doesn't exist and then move to it\n",
    "    # Repeat this for every subdirectory\n",
    "    for dir_name in directory_names:\n",
    "        top_directory_name = join(top_directory_name, dir_name)\n",
    "        if not exists(top_directory_name):\n",
    "            mkdir(dir_name)\n",
    "        chdir(dir_name)\n",
    "\n",
    "    # Save the file at the given path\n",
    "    file_path = \"./\" + file_name\n",
    "    cv2.imwrite(file_path, img)\n",
    "    chdir(cwd)\n",
    "\n",
    "\n",
    "##\n",
    "#   Get processed training data as dataframe\n",
    "##\n",
    "\n",
    "def get_train_df(process_method_directory = METHOD_A_DIRECTORY):\n",
    "    \"\"\"\n",
    "    Given a preprocessing directory, returns a dataframe with the training images and their labels.\n",
    "    Uses caching to speed up loading.\n",
    "    :param process_method_directory: The preprocessing directory to load.\n",
    "    :return: The dataframe with training data and labels.\n",
    "    \"\"\"\n",
    "    pickle_name = process_method_directory + \".pkl\"\n",
    "    pickle_path = \"processed/\" + pickle_name\n",
    "    \n",
    "    try:\n",
    "        # Try to read the training pickle, if it exists\n",
    "        train_pickle = pd.read_pickle(pickle_path)\n",
    "    except:\n",
    "        # The training pickle doesn't exist, so we create one and return it\n",
    "        train_images = {}\n",
    "        for _, row in train_data.iterrows():\n",
    "            \n",
    "            # Read image\n",
    "            id, filename = row['id'], row['filename']\n",
    "            image = cv2.imread(\"processed/\" + process_method_directory + \"/\" + row['filename'], 0)\n",
    "            train_images[id] = {\n",
    "                \"data\": image,\n",
    "                \"label\": row['label']\n",
    "            }\n",
    "        train_pickle = pd.DataFrame.from_dict(train_images, orient='index')\n",
    "        train_pickle.to_pickle(pickle_path)\n",
    "    return train_pickle\n",
    "\n",
    "\n",
    "if SETTINGS[\"PREPROCESS\"]:\n",
    "\n",
    "    # Maps of file names to CV2 images\n",
    "    train_images = {}\n",
    "    test_images = {}\n",
    "    \n",
    "    min_train_image_width = sys.maxsize\n",
    "    min_train_image_height = sys.maxsize\n",
    "    \n",
    "    ##\n",
    "    #   Traverse train images and record smallest dimension\n",
    "    ##\n",
    "    \n",
    "    # Find the smallest training image, storing the images as they're traversed\n",
    "    for _, row in train_data.iterrows():\n",
    "        \n",
    "        # Read image\n",
    "        id, filename = row['id'], row['filename']\n",
    "        image = cv2.imread(row['filename'])\n",
    "        train_images[id] = image\n",
    "        \n",
    "        # Record minimum height and width\n",
    "        height, width, _ = image.shape\n",
    "        min_train_image_width = min(min_train_image_width, width)\n",
    "        min_train_image_height = min(min_train_image_height, height)\n",
    "    \n",
    "    # Instantiate the smallest size of the two dimensions in another variable\n",
    "    min_train_image_size = min(min_train_image_width, min_train_image_height)\n",
    "    \n",
    "    ##\n",
    "    #   Traverse test images only\n",
    "    ##\n",
    "    \n",
    "    for _, row in test_data.iterrows():\n",
    "        \n",
    "        # Read image\n",
    "        id, filename = row['id'], row['filename']\n",
    "        image = cv2.imread(row['filename'])\n",
    "        test_images[id] = image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def resize_and_pad(cv2_img, to_size, padding_color=0):\n",
    "    \"\"\"\n",
    "    Resize the given CV2 image to a square with the given size length, and then pad it with the given color.\n",
    "    Adapted from https://stackoverflow.com/questions/44720580/resize-image-canvas-to-maintain-square-aspect-ratio-in-python-opencv.\n",
    "    :param cv2_img: The CV2 image obtained via cv2.imread(...).\n",
    "    :param to_size: The desired size int.\n",
    "    :param padding_color: A color int, list, tuple, or ndarray.\n",
    "    :return: The padded image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create height and width variables for better naming\n",
    "    to_height = to_width = to_size\n",
    "\n",
    "    # Get actual image dimensions\n",
    "    height, width = cv2_img.shape[:2]\n",
    "    aspect_ratio = width / height\n",
    "\n",
    "    # Interpolate differently based on the image's relative size\n",
    "    if height > to_height or width > to_width:\n",
    "        # Shrink image via inter area as its too large\n",
    "        interp = cv2.INTER_AREA\n",
    "    else:\n",
    "        # Stretch image via inter cubic as its too small\n",
    "        interp = cv2.INTER_CUBIC\n",
    "\n",
    "    is_image_horizontal = aspect_ratio > 1\n",
    "    is_image_vertical = aspect_ratio < 1\n",
    "    \n",
    "    # Height and width we're resizing the image to\n",
    "    new_height, new_width = to_height, to_width\n",
    "    \n",
    "    # Padding around the new image's inner edges\n",
    "    pad_left, pad_right, pad_top, pad_bot = 0, 0, 0, 0\n",
    "\n",
    "    if is_image_horizontal:\n",
    "        # Image is horizontal, so requires vertical padding\n",
    "        new_height = np.round(new_width / aspect_ratio).astype(int)\n",
    "        pad_vert = (to_height - new_height) / 2\n",
    "        pad_top, pad_bot = np.floor(pad_vert).astype(int), np.ceil(pad_vert).astype(int)\n",
    "\n",
    "    elif is_image_vertical:\n",
    "        # Image is vertical, so required horizontal padding\n",
    "        new_width = np.round(new_height * aspect_ratio).astype(int)\n",
    "        pad_horiz = (to_width - new_width) / 2\n",
    "        pad_left, pad_right = np.floor(pad_horiz).astype(int), np.ceil(pad_horiz).astype(int)\n",
    "\n",
    "    # If only one color is provided and the image is RGB, then set the padding color to an array of length 3\n",
    "    if len(cv2_img.shape) is 3 and not isinstance(padding_color, (list, tuple, np.ndarray)):\n",
    "        padding_color = [padding_color] * 3\n",
    "\n",
    "    # Resize the image to the newly calculated dimensions and interpolation strategy\n",
    "    new_img = cv2.resize(cv2_img, (new_width, new_height), interpolation=interp)\n",
    "    \n",
    "    # Add the calculated borders around the image\n",
    "    new_img = cv2.copyMakeBorder(new_img, pad_top, pad_bot, pad_left, pad_right, borderType=cv2.BORDER_CONSTANT, value=padding_color)\n",
    "\n",
    "    return new_img\n",
    "\n",
    "if SETTINGS[\"PREPROCESS\"] and SETTINGS[\"PREPROCESS_METHOD_A\"]:\n",
    "\n",
    "    # Add a black border around the resized images\n",
    "    COLOR = 0\n",
    "    \n",
    "    ##\n",
    "    #   Resize Training Data\n",
    "    ##\n",
    "    \n",
    "    # Resize and write training images\n",
    "    for id in train_images.keys():\n",
    "        train_image = train_images[id]\n",
    "        resized_train_image = resize_and_pad(train_image, min_train_image_size, COLOR)\n",
    "        image_dir = PROCESSED_DIRECTORY + \"/\" + METHOD_A_DIRECTORY + \"/train/img-\" + str(id) + \".jpeg\"\n",
    "        relative_imwrite(image_dir, resized_train_image)\n",
    "    \n",
    "    ##\n",
    "    #   Resize Test Data\n",
    "    ##\n",
    "    \n",
    "    # Resize and write testing images\n",
    "    for id in test_images.keys():\n",
    "        test_image = test_images[id]\n",
    "        resized_test_image = resize_and_pad(test_image, min_train_image_size, COLOR)\n",
    "        image_dir = PROCESSED_DIRECTORY + \"/\" + METHOD_A_DIRECTORY + \"/test/img-\" + str(id) + \".jpeg\"\n",
    "        relative_imwrite(image_dir, resized_test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def resize_ignoring_aspect_ratio(cv2_img, to_width, to_height):\n",
    "    \"\"\"\n",
    "    Resizes the image to the given size, ignoring aspect ratio.\n",
    "    :param cv2_img: The image to resize.\n",
    "    :param to_width: The desired width.\n",
    "    :param to_height: The desired height.\n",
    "    :return: A new, resized cv2 image.\n",
    "    \"\"\"\n",
    "    return cv2.resize(cv2_img, (to_width, to_height), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "if SETTINGS[\"PREPROCESS\"] and SETTINGS[\"PREPROCESS_METHOD_B\"]:\n",
    "    \n",
    "    ##\n",
    "    #   Resize Training Data\n",
    "    ##\n",
    "    \n",
    "    # Resize and write training images\n",
    "    for id in train_images.keys():\n",
    "        train_image = train_images[id]\n",
    "        resized_train_image = resize_ignoring_aspect_ratio(train_image, min_train_image_width, min_train_image_height)\n",
    "        image_dir = PROCESSED_DIRECTORY + \"/\" + METHOD_B_DIRECTORY + \"/train/img-\" + str(id) + \".jpeg\"\n",
    "        relative_imwrite(image_dir, resized_train_image)\n",
    "    \n",
    "    ##\n",
    "    #   Resize Test Data\n",
    "    ##\n",
    "    \n",
    "    # Resize and write testing images\n",
    "    for id in test_images.keys():\n",
    "        test_image = test_images[id]\n",
    "        resized_test_image = resize_ignoring_aspect_ratio(test_image, min_train_image_width, min_train_image_height)\n",
    "        image_dir = PROCESSED_DIRECTORY + \"/\" + METHOD_B_DIRECTORY + \"/test/img-\" + str(id) + \".jpeg\"\n",
    "        relative_imwrite(image_dir, resized_test_image)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def resize_maintaining_aspect_ratio(cv2_img, to_width, to_height):\n",
    "    \"\"\"\n",
    "    Crop the given cv2 image to the desired width and height, maintaining the image's original aspect ratio.\n",
    "    :param cv2_img: The image to crop.\n",
    "    :param to_width: The desired width.\n",
    "    :param to_height: The desired height.\n",
    "    :return: The new resized and cropped image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create height and width variables for better naming\n",
    "    height, width = cv2_img.shape[:2]\n",
    "    aspect_ratio = width / height\n",
    "    \n",
    "    # Resizing\n",
    "    max_side = max(to_height, to_width)\n",
    "    if height < width:\n",
    "        new_height = max_side\n",
    "        new_width = int(aspect_ratio * new_height)\n",
    "    else:\n",
    "        new_width = max_side\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "    resized_img = cv2.resize(cv2_img, (new_width, new_height), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "    # Cropping\n",
    "    left_padding = int((new_width - to_width) / 2)\n",
    "    right_padding = int(np.ceil((new_width - to_width) / 2))\n",
    "    top_padding = int((new_height - to_height) / 2)\n",
    "    bottom_padding = int(np.ceil((new_height - to_height) / 2))\n",
    "    cropped_img = resized_img[top_padding:(new_height - bottom_padding), left_padding:(new_width - right_padding)]\n",
    "    \n",
    "    return cropped_img\n",
    "\n",
    "if SETTINGS[\"PREPROCESS\"] and SETTINGS[\"PREPROCESS_METHOD_C\"]:\n",
    "    \n",
    "    ##\n",
    "    #   Resize Training Data\n",
    "    ##\n",
    "    \n",
    "    # Resize and write training images\n",
    "    for id in train_images.keys():\n",
    "        train_image = train_images[id]\n",
    "        resized_train_image = resize_maintaining_aspect_ratio(train_image, min_train_image_width, min_train_image_height)\n",
    "        image_dir = PROCESSED_DIRECTORY + \"/\" + METHOD_C_DIRECTORY + \"/train/img-\" + str(id) + \".jpeg\"\n",
    "        relative_imwrite(image_dir, resized_train_image)\n",
    "    \n",
    "    ##\n",
    "    #   Resize Test Data\n",
    "    ##\n",
    "    \n",
    "    # Resize and write testing images\n",
    "    for id in test_images.keys():\n",
    "        test_image = test_images[id]\n",
    "        resized_test_image = resize_maintaining_aspect_ratio(test_image, min_train_image_width, min_train_image_height)\n",
    "        image_dir = PROCESSED_DIRECTORY + \"/\" + METHOD_C_DIRECTORY + \"/test/img-\" + str(id) + \".jpeg\"\n",
    "        relative_imwrite(image_dir, resized_test_image)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def resize_to_square_maintaining_aspect_ratio(cv2_img, to_size):\n",
    "    \"\"\"\n",
    "    Wrapper around resize_maintaining_aspect_ratio to produce a cropped square image.\n",
    "    :param cv2_img: The image to crop.\n",
    "    :param to_size: The desired square side size.\n",
    "    :return: The new resized and cropped image.\n",
    "    \"\"\"\n",
    "    return resize_maintaining_aspect_ratio(cv2_img, to_size, to_size)\n",
    "\n",
    "if SETTINGS[\"PREPROCESS\"] and SETTINGS[\"PREPROCESS_METHOD_D\"]:\n",
    "    \n",
    "    ##\n",
    "    #   Resize Training Data\n",
    "    ##\n",
    "    \n",
    "    # Resize and write training images\n",
    "    for id in train_images.keys():\n",
    "        train_image = train_images[id]\n",
    "        resized_train_image = resize_to_square_maintaining_aspect_ratio(train_image, min_train_image_size)\n",
    "        image_dir = PROCESSED_DIRECTORY + \"/\" + METHOD_D_DIRECTORY + \"/train/img-\" + str(id) + \".jpeg\"\n",
    "        relative_imwrite(image_dir, resized_train_image)\n",
    "    \n",
    "    ##\n",
    "    #   Resize Test Data\n",
    "    ##\n",
    "    \n",
    "    # Resize and write testing images\n",
    "    for id in test_images.keys():\n",
    "        test_image = test_images[id]\n",
    "        resized_test_image = resize_to_square_maintaining_aspect_ratio(test_image, min_train_image_size)\n",
    "        image_dir = PROCESSED_DIRECTORY + \"/\" + METHOD_D_DIRECTORY + \"/test/img-\" + str(id) + \".jpeg\"\n",
    "        relative_imwrite(image_dir, resized_test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristical Understanding of Lung X-Rays\n",
    "\n",
    "Before proceeding, dozens of images of **normal**, **viral**, **bacterial**, and **covid**, infections (or lack thereof) were scanned. Then, one image from each class was analyzed.\n",
    "\n",
    "| Type of Infection | Image File        | Image                                                           |\n",
    "| ----------------- |:-----------------:| ---------------------------------------------------------------:|\n",
    "| Normal            | train/img-0.jpeg  | <img src=\"train/img-0.jpeg\" style=\"width:400px;height:300px\" /> |\n",
    "| Viral             | train/img-11.jpeg | <img src=\"train/img-11.jpeg\" style=\"width:400px;height:300px\" /> |\n",
    "| Bacterial         | train/img-21.jpeg | <img src=\"train/img-21.jpeg\" style=\"width:400px;height:300px\" /> |\n",
    "| COVID             | train/img-13.jpeg | <img src=\"train/img-13.jpeg\" style=\"width:400px;height:300px\" /> |\n",
    "\n",
    "#### Normal Lungs\n",
    "\n",
    "Normal lung images are usually the most contrastful and least inflammated.\n",
    "\n",
    "#### Viral Lungs\n",
    "\n",
    "Viral lungs seem deflated and have more strain-related noise around the center.\n",
    "\n",
    "#### Bacterial Lungs\n",
    "\n",
    "Bacterial lungs look very similar to viral lungs, except have more noticeable cloudiness above the lungs.\n",
    "\n",
    "#### COVID Lungs\n",
    "\n",
    "COVID (COVID-19) lungs have the most prominent deformation towards the bottom of the lungs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "Our goal is to classify every image in the testing set (`test.csv`). Thus, we will be splitting the images in `train.csv` to use for both training and validation.\n",
    "\n",
    "#### Method A – k-Fold Cross-Validation\n",
    "\n",
    "1. Choose `k` number of folds.\n",
    "2. Iterate over each fold, making that fold the **test** fold. The rest of the folds will be used for **training**.\n",
    "3. Record the model accuracy as the unweighted mean of the accuracy over each iteration.\n",
    "4. Compare the run of each classification algorithm using this method.\n",
    "\n",
    "#### Method B – Leave-One-Out Cross-Validation (LOOCV)\n",
    "\n",
    "1. Select 1 test sample.\n",
    "2. Train on n - 1 samples and record the accuracy.\n",
    "3. Repeat for the entire training set and record the model accuracy as the unweuighted mean of the accuracy over each iteration.\n",
    "4. Compare the run of each classification algorithm using this method.\n",
    "\n",
    "\n",
    "##### Every classifier will run through each of these techniques. Then,\n",
    "- if a classifier has greatest accuracy for both validation methods A and B, then the most accurate classifier was found.\n",
    "- if each method produces a different most accurate classifier, we will pick the classifier that produced the highest accuracy from either of these methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def k_fold_cv(classifier, train_data, k, *classifier_args):\n",
    "    \"\"\"\n",
    "    :param classifier: Function that takes in (training data, test data, classifier_args) and returns a testing accuracy.\n",
    "    :param train_data: List of training data to validate on, with labels.\n",
    "    :param k: The number of folds to train on.\n",
    "    :return: The mean classifier accuracy over all folds.\n",
    "    \"\"\"\n",
    "    total_accuracy = 0\n",
    "    for i in range(k):\n",
    "        test_fold = np.array(train_data[i * k : (i + 1) * k])\n",
    "        train_fold = np.array(train_data[0 : i * k] + train_data[(i + 1) * k :])\n",
    "        accuracy = classifier(train_fold, test_fold, classifier_args)\n",
    "        total_accuracy += accuracy\n",
    "    mean_accuracy = 0 if total_accuracy is 0 else (total_accuracy / k)\n",
    "    return mean_accuracy\n",
    "\n",
    "def loo_cv(classifier, train_data, *classifier_args):\n",
    "    \"\"\"\n",
    "    :param classifier: Function that takes in (training data, test data, classifier_args) and returns a testing accuracy.\n",
    "                       Same as k-fold for k = 1.\n",
    "    :param train_data: List of training data to validate on, with labels.\n",
    "    :return: The mean classifier accuracy over all folds.\n",
    "    \"\"\"\n",
    "    return k_fold_cv(classifier, train_data, 1, classifier_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification\n",
    "\n",
    "We'll now lay the pros and cons for, expectations of, and variations of each classifier that can perform classification of each lung image into\n",
    "the classes $ Y \\in \\{ \\text{normal}, \\text{viral}, \\text{bacterial}, \\text{covid} \\} $.\n",
    "\n",
    "#### Method A – SVM with Various Kernels\n",
    "\n",
    "##### Process\n",
    "1. Flatten the image into a one-dimensional vector, each component representing the shading of the image from 0 to 1.\n",
    "\n",
    "...\n",
    "\n",
    "#### Method B – 10-Layer Neural Network (NN)\n",
    "\n",
    "##### Process\n",
    "1. Flatten the image into a one-dimensional vector, each component representing the shading of the image from 0 to 1.\n",
    "\n",
    "...\n",
    "\n",
    "#### Method C – 2-Layer Convolutional Neural Net (CNN) feeding into 10-Layer NN from Method B\n",
    "\n",
    "##### Description\n",
    "Convolutional neural networks \n",
    "\n",
    "##### Pros\n",
    "- Multi-layer\n",
    "- Faster to get started\n",
    "- More fine-tuned versus regular CNN\n",
    "\n",
    "##### Cons\n",
    "- Comparatively slow\n",
    "- Parameter tuning is more difficult\n",
    "- Needs a big dataset\n",
    "\n",
    "#### Method C – Pre-Trained ResNet50 (using `keras`)\n",
    "\n",
    "##### Description\n",
    "The ResNet is a pre-trained model that learns the residuals of the input layer. Like in regression, a residual is the difference between\n",
    "observed and expected values of data. As evident from its name, this ResNet has 50 layers, and it has repeatedly been shown that training using\n",
    "this model is easier than training conventional CNNs.\n",
    "\n",
    "##### Pros\n",
    "- Multi-layer\n",
    "- Faster to get started\n",
    "- More fine-tuned versus regular CNN\n",
    "\n",
    "##### Cons\n",
    "- Comparatively slow\n",
    "- Parameter tuning is more difficult\n",
    "- Needs a big dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "LABELS = [ 'normal', 'viral', 'bacterial', 'covid' ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Method A\n",
    "\n",
    "##### Statistics\n",
    "\n",
    "C = 0.01, epochs = 1000, eps = 0.0001: accuracy: 0.8333333333333334"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  if sys.path[0] == '':\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "0.8333333333333334"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 72
    }
   ],
   "source": [
    "def sigmoid(w, x):\n",
    "    return 1 / (1 + np.exp(-np.dot(w, x)))\n",
    "\n",
    "def classifier_svm(train_data, test_data, epochs = 1000, C = 0.1, ε = 0.0001):\n",
    "    \n",
    "    # For each label, do a one-versus-all classification and add it to the test_data frame\n",
    "    for focus_label in LABELS:\n",
    "        # Learn weights for the focus label\n",
    "        w = learn_weights(train_data, epochs, C, ε, focus_label)\n",
    "\n",
    "        # Create a column for the classification result for the explicit focus label\n",
    "        test_data['cls_' + focus_label] = \"\"\n",
    "        \n",
    "        # Get weight * row dot products for each row\n",
    "        for i, test_row in test_data.iterrows():\n",
    "            x = test_row.loc['data'].flatten()\n",
    "            cls_result = np.dot(w, x)\n",
    "            test_row['cls_' + focus_label] = cls_result\n",
    "        \n",
    "    # Classify each test row\n",
    "    accuracy = 0\n",
    "    for i, test_row in test_data.iterrows():\n",
    "        label = test_row.loc['label']\n",
    "        cls = LABELS[np.argmax(test_row.iloc[2:])]\n",
    "        accuracy += int(cls == label)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = 0 if accuracy == 0 else accuracy / test_data.shape[0]\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Learn weights vector\n",
    "def learn_weights(X, epochs, C, ε, focus_label):\n",
    "    get_label = lambda l: 1 if l == focus_label else -1\n",
    "    \n",
    "    # Initialize weights and lambda slack variable vectors\n",
    "    w_len = X.iloc[0].loc['data'].shape[0] * X.iloc[0].loc['data'].shape[1]\n",
    "    w = np.full(w_len, 0.0)\n",
    "    b = 0\n",
    "    \n",
    "    orig_ε = ε\n",
    "    for _ in range(epochs):\n",
    "        for index, row in X.iterrows():\n",
    "            x = row.loc['data'].flatten()\n",
    "            y = row.loc['label']\n",
    "            \n",
    "            if 1 - get_label(y) * np.dot(w, x) + b > 0:\n",
    "                w -= ε * ((1 / epochs) * w - C * get_label(y) * x)\n",
    "                b -= ε * (C / epochs)\n",
    "            else:\n",
    "                w -= ε * (w / epochs)\n",
    "            \n",
    "            ε = orig_ε / epochs\n",
    "    return w\n",
    "\n",
    "train_data = get_train_df(METHOD_D_DIRECTORY)\n",
    "\n",
    "temp_train_len = int(train_data.shape[0] * (99/100))\n",
    "train_temp = train_data.iloc[0:temp_train_len]\n",
    "test_temp = train_data.iloc[temp_train_len:]\n",
    "\n",
    "epochs = 1000\n",
    "c = 0.01\n",
    "eps = 0.0001\n",
    "\n",
    "classifier_svm(train_temp, test_temp, epochs, c, eps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}