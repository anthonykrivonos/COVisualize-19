{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "TKbmD_pnccRN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# COVisualize-19\n",
    "\n",
    "## [COMS 4771](http://www.cs.columbia.edu/~verma/classes/ml/index.html) Final Project\n",
    "\n",
    "Classifying COVID-19 patients from lung scans.\n",
    "\n",
    "Anthony Krivonos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "fe8kSs_5cnSG",
    "outputId": "71727bc8-cd51-4b8b-e165-de1e3c9c1a74"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# % cd '/content/drive'\n",
    "# % cd 'My Drive/Spring 2020/Machine Learning/AK Final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17fAicX7ccRP",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lp3wRx32ccRT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vj6aEtXKccRU",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "from os import mkdir, chdir\n",
    "from os.path import join, exists\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VcmrrhaTccRY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "6nRSDA3KccRY",
    "outputId": "9a919705-aa9a-480c-8747-88f56e85f49d",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature     Count\n",
      "normal      350\n",
      "viral       350\n",
      "bacterial   350\n",
      "covid       77\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Read CSVs into DataFrames.\n",
    "\"\"\"\n",
    "\n",
    "train_data = pd.read_csv('./train.csv')\n",
    "test_data = pd.read_csv('./test.csv')\n",
    "\n",
    "print(\"Feature     Count\")\n",
    "print(\"normal      %d\" % train_data[train_data['label'] == 'normal'].shape[0])\n",
    "print(\"viral       %d\" % train_data[train_data['label'] == 'viral'].shape[0])\n",
    "print(\"bacterial   %d\" % train_data[train_data['label'] == 'bacterial'].shape[0])\n",
    "print(\"covid       %d\" % train_data[train_data['label'] == 'covid'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CHZXu9uQccRe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Quick Settings\n",
    "\n",
    "Keep these updated, so we only have to do certain tasks (like preprocessing) once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "oaYLP83yccRf",
    "outputId": "0ce95dfe-cd92-4dcf-ce8e-44634c9ad3fc",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PREPROCESS': True,\n",
       " 'PREPROCESS_USE_MAX': True,\n",
       " 'PREPROCESS_METHOD_A': True,\n",
       " 'PREPROCESS_METHOD_B': True,\n",
       " 'PREPROCESS_METHOD_C': True,\n",
       " 'PREPROCESS_METHOD_D': True,\n",
       " 'CLASSIFY_METHOD_A': False,\n",
       " 'CLASSIFY_METHOD_B': False,\n",
       " 'CLASSIFY_METHOD_C': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SETTINGS = {\n",
    "\n",
    "    # Preprocess the images at all?\n",
    "    \"PREPROCESS\": True,\n",
    "\n",
    "    # Process images using the maximum image dimensions?\n",
    "    \"PREPROCESS_SIZE\": 0, # -1: min, 0: median, 1: max\n",
    "    \n",
    "    # Preprocess the images using specific methods. PREPROCESS must also be True.\n",
    "    \"PREPROCESS_METHOD_A\": True,\n",
    "    \"PREPROCESS_METHOD_B\": True,\n",
    "    \"PREPROCESS_METHOD_C\": True,\n",
    "    \"PREPROCESS_METHOD_D\": True,\n",
    "    \n",
    "    # Classify the images using specific methods\n",
    "    \"CLASSIFY_METHOD_A\": False,\n",
    "    \"CLASSIFY_METHOD_B\": False,\n",
    "    \"CLASSIFY_METHOD_C\": False\n",
    "    \n",
    "}\n",
    "\n",
    "SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JLR3jdtcccRk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Image Preprocessing\n",
    "\n",
    "Original Image Example:\n",
    "<img src=\"train/img-0.jpeg\" style=\"width:400px;height:300px\" />\n",
    "\n",
    "\n",
    "For each of the following processing methods, [CLAHE(Contrast Limited Adaptive Histogram Equalization)](https://www.kaggle.com/seriousran/image-pre-processing-for-chest-x-ray) will be applied to increase the contrast of training and testing images.\n",
    "\n",
    "#### Method A – Square images w/ padding\n",
    "\n",
    "1. Find smallest-dimension training image dimension. This will be the standard image size for both training and testing.\n",
    "2. Take this image's larger dimension and resize all images into squares with that side length. While doing this, center the images and pad the left and right sides.\n",
    "\n",
    "Example:\n",
    "<img src=\"processed/method_a/train/img-0.jpeg\" style=\"width:400px;height:300px\" />\n",
    "\n",
    "#### Method B – Crop images, ignoring aspect ratio\n",
    "\n",
    "1. Find smallest-dimension training image dimensions. This will be the standard image size for both training and testing.\n",
    "2. Resize every image to this height and width, ignoring the aspect ratio of each image.\n",
    "\n",
    "Example:\n",
    "<img src=\"processed/method_b/train/img-0.jpeg\" style=\"width:400px;height:300px\" />\n",
    "\n",
    "#### Method C – Crop images to smallest size, maintaining aspect ratio\n",
    "\n",
    "1. Find smallest-dimension training image dimensions. This will be the standard image size for both training and testing.\n",
    "2. Resize and crop every image to this height and width, maintaining the aspect ratio of each image and centering its source.\n",
    "\n",
    "Example:\n",
    "<img src=\"processed/method_c/train/img-0.jpeg\" style=\"width:400px;height:300px\" />\n",
    "\n",
    "#### Method D – Crop images to square, maintaining aspect ratio\n",
    "\n",
    "1. Find smallest-dimension training image dimension. This will be the standard image size for both training and testing.\n",
    "2. Resize and crop every image to this size, maintaining the aspect ratio of each image and centering its source.\n",
    "\n",
    "Example:\n",
    "<img src=\"processed/method_d/train/img-0.jpeg\" style=\"width:400px;height:400px\" />\n",
    "\n",
    "##### Tools\n",
    "- Uses OpenCV (`CV2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "93a5c8e1fd6e48e4842a3ff889d1563e",
      "d0e4fda1c8334a2a80c5ab54d966cc58",
      "edc70c03a07a402aa75f4a0faabee760",
      "f4985a3e43c440febcd0c2e887be9d06",
      "5e2fec75767b430984ec2fc193b3ee91",
      "9ee5508d2e214ad083d08bb038e984f6",
      "7e25455b9492426f9dd6a3186436c6c3",
      "ff49719ad32d4d7fb1c609b994c10cad",
      "6bf38f1c96a84d48813aacaef6239af8",
      "c11768d0e07b424786c45d22f54e5fcf",
      "afa2d93f97a6478dabd4fbdbacba2777",
      "a571fa2a204c4f9fae4be93b434e8e5e",
      "725586f794a24e5e8ba5e564021d998b",
      "0672538686ae4cf0a2de1d698e86c65f",
      "65a2503bb593495780a512bbe2d6b45b",
      "c9eb9820e7cd4d64b77238171f8229d2"
     ]
    },
    "colab_type": "code",
    "id": "TvSwO_RXccRl",
    "outputId": "1d3b448c-50aa-4546-f648-6bb5a2c8473e",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4924bb59ac425794bb0a71dd09beba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Storing train rows for preprocessing', max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b7c60383a142668dfb31d93a83a49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Storing test rows for pre-processing', max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "#   Directory Names\n",
    "##\n",
    "\n",
    "# Name of the directory to put the processed images in\n",
    "PROCESSED_DIRECTORY = 'processed'\n",
    "\n",
    "# Different process method directories\n",
    "METHOD_A_DIRECTORY = 'method_a'\n",
    "METHOD_B_DIRECTORY = 'method_b'\n",
    "METHOD_C_DIRECTORY = 'method_c'\n",
    "METHOD_D_DIRECTORY = 'method_d'\n",
    "\n",
    "\n",
    "##\n",
    "#   Image Writing Helper Function\n",
    "##\n",
    "def relative_imwrite(relative_filepath, img):\n",
    "    \"\"\"\n",
    "    Call cv2.imwrite(..., img) on a relative file path.\n",
    "    :param relative_filepath: The path (i.e. 'processed/train/img-2.jpeg').\n",
    "    :param img: The cv2 image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Store current working directory so we can navigate back\n",
    "    cwd = os.getcwd()\n",
    "    \n",
    "    # Get index of last slash to use it as a splitting point\n",
    "    split_idx = relative_filepath.rindex(\"/\")\n",
    "    \n",
    "    # Create a relative path and filename from this\n",
    "    relative_path = relative_filepath[:split_idx]\n",
    "    file_name = relative_filepath[(split_idx + 1):]\n",
    "    \n",
    "    # Extract the directory names\n",
    "    directory_names = relative_path.split(\"/\")\n",
    "    top_directory_name = cwd\n",
    "    \n",
    "    # Create the directory if it doesn't exist and then move to it\n",
    "    # Repeat this for every subdirectory\n",
    "    for dir_name in directory_names:\n",
    "        top_directory_name = join(top_directory_name, dir_name)\n",
    "        if not exists(top_directory_name):\n",
    "            mkdir(dir_name)\n",
    "        chdir(dir_name)\n",
    "\n",
    "    # Save the file at the given path\n",
    "    file_path = \"./\" + file_name\n",
    "    cv2.imwrite(file_path, img)\n",
    "    chdir(cwd)\n",
    "\n",
    "\n",
    "##\n",
    "#   Get processed training data as dataframe\n",
    "##\n",
    "\n",
    "def get_df(process_method_directory = METHOD_A_DIRECTORY, type = \"train\"):\n",
    "    \"\"\"\n",
    "    Given a preprocessing directory, returns a dataframe with images and their labels.\n",
    "    Uses caching to speed up loading.\n",
    "    :param process_method_directory: The preprocessing directory to load.\n",
    "    :param type: \"train\" or \"test\"\n",
    "    :return: The dataframe with training or testing data and labels.\n",
    "    \"\"\"\n",
    "    pickle_name = process_method_directory + \"_\" + type + \".pkl\"\n",
    "    pickle_path = \"processed/\" + pickle_name\n",
    "    \n",
    "    try:\n",
    "        # Try to read the pickle, if it exists\n",
    "        data = pd.read_pickle(pickle_path)\n",
    "    except:\n",
    "        # The pickle doesn't exist, so we create one and return it\n",
    "        images = {}\n",
    "        data = train_data if type == \"train\" else test_data\n",
    "        for _, row in tqdm(data.iterrows(), desc=\"Loading %s data\" % type, leave = False):\n",
    "            \n",
    "            # Read image\n",
    "            id, filename = row['id'], row['filename']\n",
    "            image = cv2.imread(\"processed/\" + process_method_directory + \"/\" + row['filename'], 0)\n",
    "            if type == \"train\":\n",
    "                images[id] = {\n",
    "                    \"data\": image,\n",
    "                    \"label\": row['label']\n",
    "                }\n",
    "            else:\n",
    "                images[id] = {\n",
    "                    \"data\": image\n",
    "                }\n",
    "        data = pd.DataFrame.from_dict(images, orient='index')\n",
    "        data.to_pickle(pickle_path)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "if SETTINGS[\"PREPROCESS\"]:\n",
    "\n",
    "    # Maps of file names to CV2 images\n",
    "    train_images = {}\n",
    "    test_images = {}\n",
    "    \n",
    "    min_train_image_width = sys.maxsize\n",
    "    min_train_image_height = sys.maxsize\n",
    "    max_train_image_width = 0\n",
    "    max_train_image_height = 0\n",
    "    \n",
    "    ##\n",
    "    #   Traverse train images and record smallest dimension\n",
    "    ##\n",
    "    \n",
    "    # Find the smallest and largest training images, storing the images as they're traversed\n",
    "    for _, row in tqdm(train_data.iterrows(), desc=\"Storing train rows for preprocessing\"):\n",
    "        \n",
    "        # Read image\n",
    "        id, filename = row['id'], row['filename']\n",
    "        image = cv2.imread(row['filename'])\n",
    "        train_images[id] = image\n",
    "        \n",
    "        # Record minimum height and width\n",
    "        height, width, _ = image.shape\n",
    "        min_train_image_width = min(min_train_image_width, width)\n",
    "        min_train_image_height = min(min_train_image_height, height)\n",
    "        max_train_image_width = max(max_train_image_width, width)\n",
    "        max_train_image_height = max(max_train_image_height, height)\n",
    "    \n",
    "    # Instantiate the smallest and largest sizes of the two dimensions in another variable\n",
    "    min_train_image_size = min(min_train_image_width, min_train_image_height)\n",
    "    max_train_image_size = max(max_train_image_width, max_train_image_height)\n",
    "    \n",
    "    ##\n",
    "    #   Traverse test images only\n",
    "    ##\n",
    "    \n",
    "    for _, row in tqdm(test_data.iterrows(), desc=\"Storing test rows for pre-processing\"):\n",
    "        \n",
    "        # Read image\n",
    "        id, filename = row['id'], row['filename']\n",
    "        image = cv2.imread(row['filename'])\n",
    "        test_images[id] = image\n",
    "\n",
    "    # Initialize CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit = 2.0, tileGridSize = (16, 16))\n",
    "\n",
    "    if SETTINGS[\"PREPROCESS_SIZE\"] == 1:\n",
    "        train_image_height = max_train_image_height\n",
    "        train_image_width = max_train_image_width\n",
    "        train_image_size = max_train_image_size\n",
    "    elif SETTINGS[\"PREPROCESS_SIZE\"] == -1:\n",
    "        train_image_height = min_train_image_height\n",
    "        train_image_width = min_train_image_width\n",
    "        train_image_size = min_train_image_size\n",
    "    else:\n",
    "        train_image_height = int((max_train_image_height - min_train_image_height) / 2)\n",
    "        train_image_width = int((max_train_image_width - min_train_image_height) / 2)\n",
    "        train_image_size = int((max_train_image_size - min_train_image_size) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SgHjRsF9ccRp"
   },
   "source": [
    "#### Method A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "a4260eaa1fcb414ea1cb2c6e75ebb8e3",
      "b4c0508a55f34327a1b78e04fd0ffcdd",
      "6eb6c738b43f4c5cba142c4ca555df14",
      "4de47902a1f94cd79e476c7722a32cc7",
      "cd7c589e40584cdbb369082ed41fbd7f",
      "de315c4e32854acf875f204e5f142f16",
      "81262396b68140a3b681e19f981c9828",
      "65a9dba714f64c81bf6e3ecb12343fc8",
      "58df504c932549c990c3323e067d9c81",
      "f918089279f645618d3b9b21ac01f8db",
      "f1c4168f39634312b2075e0562d80c7c",
      "37913a7857b544d19e3ee8618e0194a7",
      "a1a3e17521e14fb1997ad4b67afb57ee",
      "7b91d23b597f4a7c9ecdd665a8f36337",
      "69fb7085f0e040909dba1ab4349b323a",
      "fc9d64d7c55942cdb1b47b79daafcbd1"
     ]
    },
    "colab_type": "code",
    "id": "W5W7ASoHccRp",
    "outputId": "fc71d2ef-18ce-47d1-ae67-cb69a6c2384b",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700089885b424f21aa9da4d18116d649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Method A on train data', max=1127, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c16378177f24556a3a82b2632bd4824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Method A on test data', max=484, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def resize_and_pad(cv2_img, to_size, padding_color=0):\n",
    "    \"\"\"\n",
    "    Resize the given CV2 image to a square with the given size length, and then pad it with the given color.\n",
    "    Adapted from https://stackoverflow.com/questions/44720580/resize-image-canvas-to-maintain-square-aspect-ratio-in-python-opencv.\n",
    "    :param cv2_img: The CV2 image obtained via cv2.imread(...).\n",
    "    :param to_size: The desired size int.\n",
    "    :param padding_color: A color int, list, tuple, or ndarray.\n",
    "    :return: The padded image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create height and width variables for better naming\n",
    "    to_height = to_width = to_size\n",
    "\n",
    "    # Get actual image dimensions\n",
    "    height, width = cv2_img.shape[:2]\n",
    "    aspect_ratio = width / height\n",
    "\n",
    "    # Interpolate differently based on the image's relative size\n",
    "    if height > to_height or width > to_width:\n",
    "        # Shrink image via inter area as its too large\n",
    "        interp = cv2.INTER_AREA\n",
    "    else:\n",
    "        # Stretch image via inter cubic as its too small\n",
    "        interp = cv2.INTER_CUBIC\n",
    "\n",
    "    is_image_horizontal = aspect_ratio > 1\n",
    "    is_image_vertical = aspect_ratio < 1\n",
    "    \n",
    "    # Height and width we're resizing the image to\n",
    "    new_height, new_width = to_height, to_width\n",
    "    \n",
    "    # Padding around the new image's inner edges\n",
    "    pad_left, pad_right, pad_top, pad_bot = 0, 0, 0, 0\n",
    "\n",
    "    if is_image_horizontal:\n",
    "        # Image is horizontal, so requires vertical padding\n",
    "        new_height = np.round(new_width / aspect_ratio).astype(int)\n",
    "        pad_vert = (to_height - new_height) / 2\n",
    "        pad_top, pad_bot = np.floor(pad_vert).astype(int), np.ceil(pad_vert).astype(int)\n",
    "\n",
    "    elif is_image_vertical:\n",
    "        # Image is vertical, so required horizontal padding\n",
    "        new_width = np.round(new_height * aspect_ratio).astype(int)\n",
    "        pad_horiz = (to_width - new_width) / 2\n",
    "        pad_left, pad_right = np.floor(pad_horiz).astype(int), np.ceil(pad_horiz).astype(int)\n",
    "\n",
    "    # If only one color is provided and the image is RGB, then set the padding color to an array of length 3\n",
    "    if len(cv2_img.shape) is 3 and not isinstance(padding_color, (list, tuple, np.ndarray)):\n",
    "        padding_color = [padding_color] * 3\n",
    "\n",
    "    # Resize the image to the newly calculated dimensions and interpolation strategy\n",
    "    new_img = cv2.resize(cv2_img, (new_width, new_height), interpolation=interp)\n",
    "    \n",
    "    # Add the calculated borders around the image\n",
    "    new_img = cv2.copyMakeBorder(new_img, pad_top, pad_bot, pad_left, pad_right, borderType=cv2.BORDER_CONSTANT, value=padding_color)\n",
    "\n",
    "    # Make image grayscale\n",
    "    new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    return new_img\n",
    "\n",
    "if SETTINGS[\"PREPROCESS\"] and SETTINGS[\"PREPROCESS_METHOD_A\"]:\n",
    "\n",
    "    # Add a black border around the resized images\n",
    "    COLOR = 0\n",
    "    \n",
    "    ##\n",
    "    #   Resize Training Data\n",
    "    ##\n",
    "    \n",
    "    # Resize and write training images\n",
    "    for id in tqdm(train_images.keys(), desc=\"Method A on train data\"):\n",
    "        train_image = train_images[id]\n",
    "        resized_train_image = resize_and_pad(train_image, train_image_size, COLOR)\n",
    "        clahe_train_image = clahe.apply(resized_train_image)\n",
    "        image_dir = PROCESSED_DIRECTORY + \"/\" + METHOD_A_DIRECTORY + \"/train/img-\" + str(id) + \".jpeg\"\n",
    "        relative_imwrite(image_dir, clahe_train_image)\n",
    "    \n",
    "    ##\n",
    "    #   Resize Test Data\n",
    "    ##\n",
    "    \n",
    "    # Resize and write testing images\n",
    "    for id in tqdm(test_images.keys(), desc=\"Method A on test data\"):\n",
    "        test_image = test_images[id]\n",
    "        resized_test_image = resize_and_pad(test_image, min_train_image_size, COLOR)\n",
    "        clahe_test_image = clahe.apply(resized_test_image)\n",
    "        image_dir = PROCESSED_DIRECTORY + \"/\" + METHOD_A_DIRECTORY + \"/test/img-\" + str(id) + \".jpeg\"\n",
    "        relative_imwrite(image_dir, clahe_test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hKg2ayWIccRt"
   },
   "source": [
    "#### Method B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "33157261d8904ba2a738f5f3db6e7ab8",
      "50df7cb2f9954d149c541e7e46c6a018",
      "85e8552356a14da8a1d51ccdce6b966f",
      "6f556035b5b541c09ce47e7c896b5088",
      "cd299e21f41c4688bbde1379511f88f8",
      "3831024e35bf423cb091b1693d71144f",
      "4b27e4e9df86493d8a08d634cd4485e5",
      "7c963475afdc4e5592c90a513cf35172",
      "e6ed0a311137403dba43b46b8625a323",
      "911825bc23da4dc49f35455738046005",
      "6e8b6652439e4379a783931539e16e12",
      "51b32880599b4c648aa69235c1c447eb",
      "c4ec4b16d30c42fb91d37bc824d4047c",
      "51c0894a22ff4ed892229ab7507b249f",
      "fbf018a0c07d44de9227ce02d25eb748",
      "3964aeaa8a544157a3dd2c259e833a01"
     ]
    },
    "colab_type": "code",
    "id": "3MkRS0QgccRu",
    "outputId": "83d8d3b2-346a-458d-f2de-23be64e7a1e3",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5489f18c2340099542934c9a9362d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Method B on train data', max=1127, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63aa7651a574d459f9fbfde190d96a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Method B on test data', max=484, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def resize_ignoring_aspect_ratio(cv2_img, to_width, to_height):\n",
    "    \"\"\"\n",
    "    Resizes the image to the given size, ignoring aspect ratio.\n",
    "    :param cv2_img: The image to resize.\n",
    "    :param to_width: The desired width.\n",
    "    :param to_height: The desired height.\n",
    "    :return: A new, resized cv2 image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Resize the image\n",
    "    new_img = cv2.resize(cv2_img, (to_width, to_height), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Make image grayscale\n",
    "    new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    return new_img\n",
    "\n",
    "if SETTINGS[\"PREPROCESS\"] and SETTINGS[\"PREPROCESS_METHOD_B\"]:\n",
    "    \n",
    "    ##\n",
    "    #   Resize Training Data\n",
    "    ##\n",
    "    \n",
    "    # Resize and write training images\n",
    "    for id in tqdm(train_images.keys(), desc=\"Method B on train data\"):\n",
    "        train_image = train_images[id]\n",
    "        resized_train_image = resize_ignoring_aspect_ratio(train_image, train_image_width, train_image_height)\n",
    "        clahe_train_image = clahe.apply(resized_train_image)\n",
    "        image_dir = PROCESSED_DIRECTORY + \"/\" + METHOD_B_DIRECTORY + \"/train/img-\" + str(id) + \".jpeg\"\n",
    "        relative_imwrite(image_dir, clahe_train_image)\n",
    "    \n",
    "    ##\n",
    "    #   Resize Test Data\n",
    "    ##\n",
    "    \n",
    "    # Resize and write testing images\n",
    "    for id in tqdm(test_images.keys(), desc=\"Method B on test data\"):\n",
    "        test_image = test_images[id]\n",
    "        resized_test_image = resize_ignoring_aspect_ratio(test_image, train_image_width, train_image_height)\n",
    "        clahe_test_image = clahe.apply(resized_test_image)\n",
    "        image_dir = PROCESSED_DIRECTORY + \"/\" + METHOD_B_DIRECTORY + \"/test/img-\" + str(id) + \".jpeg\"\n",
    "        relative_imwrite(image_dir, clahe_test_image)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5pKCHw5_ccRx"
   },
   "source": [
    "#### Method C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "2429ec87a6b04ce79acee1a2d1c0fedb",
      "84aca0dba76e490f80d05a78b1f85df8",
      "06cfc1935baf44709af70396b0e65989",
      "1621e167f9f14c5b9963c0950e70a9b3",
      "5978493a64214f4b84b7455c15241012",
      "4e6c5462869947bfa40a0b1330c91705",
      "3b17d96139d04f07923cf181c2f3c962",
      "5fe89707f2a649b89a86e88af49aee8b"
     ]
    },
    "colab_type": "code",
    "id": "999BpTJkccRx",
    "outputId": "ace097c6-dca0-4505-a432-61cdf1350955",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d912c157807d4ae78ddf0ed2e0c19d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Method C on train data', max=1127, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4839d19d4448e785ffe35d78298f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Method C on test data', max=484, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def resize_maintaining_aspect_ratio(cv2_img, to_width, to_height):\n",
    "    \"\"\"\n",
    "    Crop the given cv2 image to the desired width and height, maintaining the image's original aspect ratio.\n",
    "    :param cv2_img: The image to crop.\n",
    "    :param to_width: The desired width.\n",
    "    :param to_height: The desired height.\n",
    "    :return: The new resized and cropped image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create height and width variables for better naming\n",
    "    height, width = cv2_img.shape[:2]\n",
    "    aspect_ratio = width / height\n",
    "    \n",
    "    # Resizing\n",
    "    max_side = max(to_height, to_width)\n",
    "    if height < width:\n",
    "        new_height = max_side\n",
    "        new_width = int(aspect_ratio * new_height)\n",
    "    else:\n",
    "        new_width = max_side\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "    resized_img = cv2.resize(cv2_img, (new_width, new_height), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "    # Cropping\n",
    "    left_padding = int((new_width - to_width) / 2)\n",
    "    right_padding = int(np.ceil((new_width - to_width) / 2))\n",
    "    top_padding = int((new_height - to_height) / 2)\n",
    "    bottom_padding = int(np.ceil((new_height - to_height) / 2))\n",
    "    cropped_img = resized_img[top_padding:(new_height - bottom_padding), left_padding:(new_width - right_padding)]\n",
    "    \n",
    "    # Make image grayscale\n",
    "    new_img = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    return new_img\n",
    "\n",
    "if SETTINGS[\"PREPROCESS\"] and SETTINGS[\"PREPROCESS_METHOD_C\"]:\n",
    "    \n",
    "    ##\n",
    "    #   Resize Training Data\n",
    "    ##\n",
    "    \n",
    "    # Resize and write training images\n",
    "    for id in tqdm(train_images.keys(), desc=\"Method C on train data\"):\n",
    "        train_image = train_images[id]\n",
    "        resized_train_image = resize_maintaining_aspect_ratio(train_image, train_image_width, train_image_height)\n",
    "        clahe_train_image = clahe.apply(resized_train_image)\n",
    "        image_dir = PROCESSED_DIRECTORY + \"/\" + METHOD_C_DIRECTORY + \"/train/img-\" + str(id) + \".jpeg\"\n",
    "        relative_imwrite(image_dir, clahe_train_image)\n",
    "    \n",
    "    ##\n",
    "    #   Resize Test Data\n",
    "    ##\n",
    "    \n",
    "    # Resize and write testing images\n",
    "    for id in tqdm(test_images.keys(), desc=\"Method C on test data\"):\n",
    "        test_image = test_images[id]\n",
    "        resized_test_image = resize_maintaining_aspect_ratio(test_image, train_image_width, train_image_height)\n",
    "        clahe_test_image = clahe.apply(resized_test_image)\n",
    "        image_dir = PROCESSED_DIRECTORY + \"/\" + METHOD_C_DIRECTORY + \"/test/img-\" + str(id) + \".jpeg\"\n",
    "        relative_imwrite(image_dir, clahe_test_image)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0-kL3akyccR0"
   },
   "source": [
    "#### Method D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_UYbR5VccR1",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693aceac9b8d47079e18b8bfd63ff619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Method D on train data', max=1127, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf57afb4d3804551a0174b0d5f4d2a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Method D on test data', max=484, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def resize_to_square_maintaining_aspect_ratio(cv2_img, to_size):\n",
    "    \"\"\"\n",
    "    Wrapper around resize_maintaining_aspect_ratio to produce a cropped square image.\n",
    "    :param cv2_img: The image to crop.\n",
    "    :param to_size: The desired square side size.\n",
    "    :return: The new resized and cropped image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Resize\n",
    "    return resize_maintaining_aspect_ratio(cv2_img, to_size, to_size)\n",
    "\n",
    "\n",
    "if SETTINGS[\"PREPROCESS\"] and SETTINGS[\"PREPROCESS_METHOD_D\"]:\n",
    "    \n",
    "    ##\n",
    "    #   Resize Training Data\n",
    "    ##\n",
    "    \n",
    "    # Resize and write training images\n",
    "    for id in tqdm(train_images.keys(), desc=\"Method D on train data\"):\n",
    "        train_image = train_images[id]\n",
    "        resized_train_image = resize_to_square_maintaining_aspect_ratio(train_image, train_image_size)\n",
    "        clahe_train_image = clahe.apply(resized_train_image)\n",
    "        image_dir = PROCESSED_DIRECTORY + \"/\" + METHOD_D_DIRECTORY + \"/train/img-\" + str(id) + \".jpeg\"\n",
    "        relative_imwrite(image_dir, clahe_train_image)\n",
    "    \n",
    "    ##\n",
    "    #   Resize Test Data\n",
    "    ##\n",
    "    \n",
    "    # Resize and write testing images\n",
    "    for id in tqdm(test_images.keys(), desc=\"Method D on test data\"):\n",
    "        test_image = test_images[id]\n",
    "        resized_test_image = resize_to_square_maintaining_aspect_ratio(test_image, train_image_size)\n",
    "        clahe_test_image = clahe.apply(resized_test_image)\n",
    "        image_dir = PROCESSED_DIRECTORY + \"/\" + METHOD_D_DIRECTORY + \"/test/img-\" + str(id) + \".jpeg\"\n",
    "        relative_imwrite(image_dir, clahe_test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3FA-ZAtNccR4"
   },
   "source": [
    "### Heuristical Understanding of Lung X-Rays\n",
    "\n",
    "Before proceeding, dozens of images of **normal**, **viral**, **bacterial**, and **covid**, infections (or lack thereof) were scanned. Then, one image from each class was analyzed.\n",
    "\n",
    "| Type of Infection | Image File        | Image                                                           |\n",
    "| ----------------- |:-----------------:| ---------------------------------------------------------------:|\n",
    "| Normal            | train/img-0.jpeg  | <img src=\"train/img-0.jpeg\" style=\"width:400px;height:300px\" /> |\n",
    "| Viral             | train/img-11.jpeg | <img src=\"train/img-11.jpeg\" style=\"width:400px;height:300px\" /> |\n",
    "| Bacterial         | train/img-21.jpeg | <img src=\"train/img-21.jpeg\" style=\"width:400px;height:300px\" /> |\n",
    "| COVID             | train/img-13.jpeg | <img src=\"train/img-13.jpeg\" style=\"width:400px;height:300px\" /> |\n",
    "\n",
    "#### Normal Lungs\n",
    "\n",
    "Normal lung images are usually the most contrastful and least inflammated.\n",
    "\n",
    "#### Viral Lungs\n",
    "\n",
    "Viral lungs seem deflated and have more strain-related noise around the center.\n",
    "\n",
    "#### Bacterial Lungs\n",
    "\n",
    "Bacterial lungs look very similar to viral lungs, except have more noticeable cloudiness above the lungs.\n",
    "\n",
    "#### COVID Lungs\n",
    "\n",
    "COVID (COVID-19) lungs have the most prominent deformation towards the bottom of the lungs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ig5TVpGhccR5"
   },
   "source": [
    "### Validation\n",
    "\n",
    "Our goal is to classify every image in the testing set (`test.csv`). Thus, we will be splitting the images in `train.csv` to use for both training and validation.\n",
    "\n",
    "#### Method – k-Fold Cross-Validation\n",
    "\n",
    "1. Choose `k` number of folds.\n",
    "2. Iterate over each fold, making that fold the **test** fold. The rest of the folds will be used for **training**.\n",
    "3. Record the model accuracy as the unweighted mean of the accuracy over each iteration.\n",
    "4. Compare the run of each classification algorithm using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lFuLwc6dccR6",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def k_fold_cv(classifier, train_data, k, *classifier_args):\n",
    "    \"\"\"\n",
    "    :param classifier: Function that takes in (training data, test data, classifier_args) and returns a testing accuracy.\n",
    "    :param train_data: List of training data to validate on, with labels.\n",
    "    :param k: The number of folds to train on.\n",
    "    :return: The mean classifier accuracy over all folds.\n",
    "    \"\"\"\n",
    "    total_accuracy = 0\n",
    "    fold_size = int(train_data.shape[0] / k)\n",
    "    for i in trange(k, desc=\"k-fold (k: %d)\" % k):\n",
    "        test_fold = train_data.iloc[i * fold_size : (i + 1) * fold_size].reset_index(drop=True)\n",
    "        train_fold = pd.concat([train_data.iloc[0 : i * fold_size], train_data.iloc[(i + 1) * fold_size :]]).reset_index(drop=True)\n",
    "        accuracy = classifier(train_fold, test_fold, *classifier_args)\n",
    "        total_accuracy += accuracy\n",
    "    mean_accuracy = 0 if total_accuracy is 0 else (total_accuracy / k)\n",
    "    return mean_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YszUSqDWccR-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Classification\n",
    "\n",
    "We'll now lay the pros and cons for, expectations of, and variations of each classifier that can perform classification of each lung image into\n",
    "the classes $ Y \\in \\{ \\text{normal}, \\text{viral}, \\text{bacterial}, \\text{covid} \\} $.\n",
    "\n",
    "#### Method A – SVM with Various Kernels\n",
    "\n",
    "##### Process\n",
    "1. Flatten the image into a one-dimensional vector, each component representing the shading of the image from 0 to 1.\n",
    "\n",
    "...\n",
    "\n",
    "#### Method B – 10-Layer Neural Network (NN)\n",
    "\n",
    "##### Process\n",
    "1. Flatten the image into a one-dimensional vector, each component representing the shading of the image from 0 to 1.\n",
    "\n",
    "...\n",
    "\n",
    "#### Method C – 2-Layer Convolutional Neural Net (CNN) feeding into 10-Layer NN from Method B\n",
    "\n",
    "##### Description\n",
    "Convolutional neural networks \n",
    "\n",
    "##### Pros\n",
    "- Multi-layer\n",
    "- Faster to get started\n",
    "- More fine-tuned versus regular CNN\n",
    "\n",
    "##### Cons\n",
    "- Comparatively slow\n",
    "- Parameter tuning is more difficult\n",
    "- Needs a big dataset\n",
    "\n",
    "#### Method C – Pre-Trained ResNet50 (using `keras`)\n",
    "\n",
    "##### Description\n",
    "The ResNet is a pre-trained model that learns the residuals of the input layer. Like in regression, a residual is the difference between\n",
    "observed and expected values of data. As evident from its name, this ResNet has 50 layers, and it has repeatedly been shown that training using\n",
    "this model is easier than training conventional CNNs.\n",
    "\n",
    "##### Pros\n",
    "- Multi-layer\n",
    "- Faster to get started\n",
    "- More fine-tuned versus regular CNN\n",
    "\n",
    "##### Cons\n",
    "- Comparatively slow\n",
    "- Parameter tuning is more difficult\n",
    "- Needs a big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-3Z-h-UccR-",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LABELS = [ 'normal', 'viral', 'bacterial', 'covid' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KeM1f--CccSB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Method A\n",
    "\n",
    "##### Statistics\n",
    "\n",
    "k-fold w/ k = 10, C = 0.01, epochs = 1000, eps = 0.0001: avg accuracy: 0.8333333333333334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k2o2LEvaccSB",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def classifier_svm(train_data, test_data, epochs = 1000, C = 0.1, ε = 0.0001):\n",
    "\n",
    "    # Learn weights vector\n",
    "    def learn_weights(X, epochs, C, ε, focus_label):\n",
    "        get_label = lambda l: 1 if l == focus_label else -1\n",
    "\n",
    "        # Initialize weights and lambda slack variable vectors\n",
    "        w_len = X.iloc[0].loc['data'].shape[0] * X.iloc[0].loc['data'].shape[1]\n",
    "        w = np.full(w_len, 0.0)\n",
    "        b = 0\n",
    "\n",
    "        orig_ε = ε\n",
    "        for _ in trange(epochs, desc=\"learning weights (epochs)\", leave=False):\n",
    "            for index, row in X.iterrows():\n",
    "                x = row.loc['data'].flatten()\n",
    "                y = row.loc['label']\n",
    "\n",
    "                if 1 - get_label(y) * np.dot(w, x) + b > 0:\n",
    "                    w -= ε * ((1 / epochs) * w - C * get_label(y) * x)\n",
    "                    b -= ε * (C / epochs)\n",
    "                else:\n",
    "                    w -= ε * (w / epochs)\n",
    "\n",
    "                ε = orig_ε / epochs\n",
    "        return w\n",
    "    \n",
    "    # For each label, do a one-versus-all classification and add it to the test_data frame\n",
    "    for focus_label in tqdm(LABELS, desc=\"SVM w/GCD (epochs: %d, C: %d, ε: %d)\" % (epochs, C, ε), leave=False):\n",
    "        # Learn weights for the focus label\n",
    "        w = learn_weights(train_data, epochs, C, ε, focus_label)\n",
    "\n",
    "        # Create a column for the classification result for the explicit focus label\n",
    "        test_data['cls_' + focus_label] = \"\"\n",
    "        \n",
    "        # Get weight * row dot products for each row\n",
    "        for i, test_row in tqdm(test_data.iterrows(), desc=\"training\", leave=False):\n",
    "            x = test_row.loc['data'].flatten()\n",
    "            cls_result = np.dot(w, x)\n",
    "            test_row['cls_' + focus_label] = cls_result\n",
    "        \n",
    "    # Classify each test row\n",
    "    accuracy = 0\n",
    "    for i, test_row in tqdm(test_data.iterrows(), desc=\"classifying\", leave=False):\n",
    "        label = test_row.loc['label']\n",
    "        cls = LABELS[np.argmax(test_row.iloc[2:])]\n",
    "        accuracy += int(cls == label)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = 0 if accuracy == 0 else accuracy / test_data.shape[0]\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "if SETTINGS[\"CLASSIFY_METHOD_A\"]:\n",
    "    train_data = get_df(METHOD_D_DIRECTORY, \"train\")\n",
    "\n",
    "    epochs = 1000\n",
    "    c = 0.01\n",
    "    eps = 0.0001\n",
    "\n",
    "    k_fold_cv(classifier_svm, train_data, 10, epochs, c, eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RfrgvGdlccSE"
   },
   "source": [
    "#### Method B\n",
    "\n",
    "##### Statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPwWPJoBccSF",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def classifier_nn(train_data, test_data, hl, α = 1e-5, learn_rate = 0.001):\n",
    "    \"\"\"\n",
    "    Multi-layer perceptron neural network classifier with SGD.\n",
    "    :param train_data: Data to train on.\n",
    "    :param test_data: Data to test on.\n",
    "    :param α: L2 regularization penalty.\n",
    "    :param hl: Array of hidden layer sizes.\n",
    "    :param learn_rate: Learning rate.\n",
    "    :return: The accuracy on the test_data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # since classes are strings, we need a way to represent them numerically for the NN\n",
    "    def encode_label(label):\n",
    "        return LABELS.index(label)\n",
    "    \n",
    "    # Create training rows by flattening the images and record training labels\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, train_row in train_data.iterrows():\n",
    "        X.append(train_row['data'].flatten())\n",
    "        y.append(encode_label(train_row['label']))\n",
    "    \n",
    "    # Instantiate a multi-layer perceptron network\n",
    "    #    solver = 'sgd'                     uses stochastic gradient descent\n",
    "    #    alpha = α                          L2 regularization parameter\n",
    "    #    hidden_layer_sizes = hl            size of each hidden layer\n",
    "    #    learning_rate_init = learn_rate    starting learning rate\n",
    "    #    learning_rate = 'adaptive'         learning rate adapts to validation accuracy\n",
    "    #    early_stopping = True              stops training when validation score doesn't increase\n",
    "    #    verbose = True                     shows progress bar\n",
    "    #    random_state = 1                   seed for better data shuffling\n",
    "    nn = MLPClassifier(solver = 'sgd', \\\n",
    "                       alpha = α, \\\n",
    "                       hidden_layer_sizes = hl, \\\n",
    "                       learning_rate_init = learn_rate, \\\n",
    "#                        learning_rate = 'adaptive', \\\n",
    "                       early_stopping = True, \\\n",
    "                       verbose = True, \\\n",
    "                       random_state = 1, \\\n",
    "                       batch_size = 64 \\\n",
    "                      )\n",
    "    \n",
    "    # Fit the training data to the neural network\n",
    "    nn.fit(X, y)\n",
    "    \n",
    "    # Finally, predict the testing labels\n",
    "    test_X = []\n",
    "    test_y = []\n",
    "    \n",
    "    for i, test_row in test_data.iterrows():\n",
    "        test_X.append(test_row['data'].flatten())\n",
    "        test_y.append(encode_label(test_row['label']))\n",
    "    \n",
    "#     accuracy = nn.score(test_X, test_y)\n",
    "\n",
    "    test_labels = nn.predict(test_X)\n",
    "    \n",
    "    # Return the classification accuracy\n",
    "    accuracy = 0\n",
    "    for i in trange(len(test_y), desc=\"NN accuracy\", leave=False):\n",
    "        accuracy += int(test_y[i] == test_labels[i])\n",
    "    accuracy = 0 if accuracy == 0 else accuracy / test_data.shape[0]\n",
    "    \n",
    "    print(test_labels)\n",
    "    print(test_y)\n",
    "    \n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "if SETTINGS[\"CLASSIFY_METHOD_B\"]:\n",
    "    \n",
    "    # Preprocess the data and shuffle\n",
    "    train_data = get_df(METHOD_C_DIRECTORY, \"train\").sample(frac=1).reset_index(drop = True)\n",
    "    \n",
    "    # Test: uniformly distribute all classes\n",
    "    covid_count = train_data[train_data['label'] == 'covid'].shape[0] # least\n",
    "    train_data = pd.concat([\n",
    "        train_data[train_data['label'] == 'normal'].iloc[0:covid_count],\n",
    "        train_data[train_data['label'] == 'viral'].iloc[0:covid_count],\n",
    "        train_data[train_data['label'] == 'bacterial'].iloc[0:covid_count],\n",
    "        train_data[train_data['label'] == 'covid']\n",
    "    ]).sample(frac=1).reset_index(drop = True)\n",
    "    # End Test\n",
    "    \n",
    "    percent_train = .8\n",
    "    train_temp = train_data.iloc[0:int(train_data.shape[0] * percent_train)]\n",
    "    test_temp = train_data.iloc[int(train_data.shape[0] * percent_train):]\n",
    "    \n",
    "    layer_1_size = int(train_data.iloc[0]['data'].flatten().shape[0])\n",
    "    layer_2_size = int(layer_1_size / 2)\n",
    "    layer_3_size = int(layer_1_size / 4)\n",
    "    \n",
    "    print(classifier_nn(train_temp, test_temp, hl = [ layer_1_size, layer_2_size, layer_3_size ], learn_rate = 0.001))\n",
    "    # print(layer_size)\n",
    "    # print(k_fold_cv(classifier_nn, train_data, 4, [ int(layer_size / 2) ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ErFFoRe0ccSI"
   },
   "source": [
    "#### Method C\n",
    "\n",
    "```\n",
    "Model: \"sequential_54\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d_161 (Conv2D)          (None, 86, 86, 64)        640       \n",
    "_________________________________________________________________\n",
    "conv2d_162 (Conv2D)          (None, 84, 84, 64)        36928     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_135 (MaxPoolin (None, 42, 42, 64)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_163 (Conv2D)          (None, 40, 40, 128)       73856     \n",
    "_________________________________________________________________\n",
    "conv2d_164 (Conv2D)          (None, 38, 38, 128)       147584    \n",
    "_________________________________________________________________\n",
    "max_pooling2d_136 (MaxPoolin (None, 19, 19, 128)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_165 (Conv2D)          (None, 17, 17, 256)       295168    \n",
    "_________________________________________________________________\n",
    "conv2d_166 (Conv2D)          (None, 15, 15, 256)       590080    \n",
    "_________________________________________________________________\n",
    "conv2d_167 (Conv2D)          (None, 13, 13, 256)       590080    \n",
    "_________________________________________________________________\n",
    "flatten_34 (Flatten)         (None, 43264)             0         \n",
    "_________________________________________________________________\n",
    "dense_75 (Dense)             (None, 512)               22151680  \n",
    "_________________________________________________________________\n",
    "dropout_88 (Dropout)         (None, 512)               0         \n",
    "_________________________________________________________________\n",
    "dense_76 (Dense)             (None, 4)                 2052      \n",
    "=================================================================\n",
    "Total params: 23,888,068\n",
    "Trainable params: 23,888,068\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Train on 901 samples, validate on 226 samples\n",
    "```\n",
    "\n",
    "##### Statistics\n",
    "\n",
    "Pre-Processing A:\n",
    "- 20 epochs\n",
    "=> val. loss: 0.6592920422554016, val. accuracy: 1.3398784396395218\n",
    "\n",
    "- 40 epochs\n",
    "- ResNet152V2\n",
    "=> val_loss: 2.8966, val_accuracy: 0.6770\n",
    "\n",
    "Pre-Processing B:\n",
    "- 15 epochs\n",
    "=> val. accuracy: 0.6224188804626465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Z2lRBrrccSI",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "import keras\n",
    "from keras import utils\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.engine.input_layer import Input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Add, SeparableConv2D, Conv2D, ZeroPadding2D, MaxPooling2D, AveragePooling2D, Dropout, Dense, Flatten, LeakyReLU, Activation, BatchNormalization, UpSampling2D\n",
    "\n",
    "##\n",
    "#   CORONet Shortcuts\n",
    "##\n",
    "\n",
    "mid_layer_activation = 'relu' # 0-to-1 activation\n",
    "relu_leak = 0.3\n",
    "\n",
    "def classifier_cnn(train_data, test_data, epochs = 15, batch_size = 64, submission_data = None, model_name = 'cnn'):\n",
    "\n",
    "    # since classes are strings, we need a way to represent them numerically for the NN\n",
    "    encode_label = lambda label: LABELS.index(label)\n",
    "    decode_label = lambda index: LABELS[int(index)]\n",
    "    \n",
    "    # Store TRAINING data and labels\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, train_row in train_data.iterrows():\n",
    "        X.append(train_row['data'])\n",
    "        y.append(encode_label(train_row['label']))\n",
    "    \n",
    "    # Next, store TESTING data and lables\n",
    "    test_X = []\n",
    "    test_y = []\n",
    "    \n",
    "    for i, test_row in test_data.iterrows():\n",
    "        test_X.append(test_row['data'])\n",
    "        test_y.append(encode_label(test_row['label']))\n",
    "\n",
    "    # Store data dimensions for later use\n",
    "    row_len = len(X[0])\n",
    "    col_len = len(X[0][0])\n",
    "    train_data_len = len(X)\n",
    "    input_shape = (row_len, col_len, 3)\n",
    "    \n",
    "    # Create numerical labels from the categorical classes\n",
    "    y = utils.to_categorical(y, len(LABELS))\n",
    "    test_y = utils.to_categorical(test_y, len(LABELS))\n",
    "    \n",
    "    # Reshape training and testing features (add 2 extra channels to features for ResNet)\n",
    "    X = np.array(X)\n",
    "    X = X.reshape(X.shape[0], row_len, col_len)\n",
    "    X = np.repeat(X[..., np.newaxis], 3, -1)\n",
    "    test_X = np.array(test_X)\n",
    "    test_X = test_X.reshape(test_X.shape[0], row_len, col_len)\n",
    "    test_X = np.repeat(test_X[..., np.newaxis], 3, -1)\n",
    "\n",
    "    # Create image generators\n",
    "    train_gen = ImageDataGenerator(\n",
    "        rotation_range = 40,\n",
    "        width_shift_range = 20,\n",
    "        height_shift_range = 20,\n",
    "        shear_range = 10,\n",
    "        zoom_range = 10\n",
    "    )\n",
    "    test_gen = ImageDataGenerator(\n",
    "        rotation_range = 40,\n",
    "        width_shift_range = 20,\n",
    "        height_shift_range = 20,\n",
    "        shear_range = 10,\n",
    "        zoom_range = 10\n",
    "    )\n",
    "\n",
    "    train_gen.fit(X, augment = True, seed = 1, rounds = 1)\n",
    "    test_gen.fit(test_X, augment = True, seed = 1, rounds = 1)\n",
    "\n",
    "    train_flow = train_gen.flow(X, y, batch_size = batch_size, seed = 1, shuffle = True)\n",
    "    test_flow = test_gen.flow(test_X, test_y, batch_size = batch_size, seed = 1, shuffle = True)\n",
    "\n",
    "    ##\n",
    "    #   CORONet Layers\n",
    "    ##\n",
    "\n",
    "    base = ResNet50(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
    "\n",
    "    for layer in base.layers:\n",
    "      layer.trainable = False\n",
    "\n",
    "    # Pool and flatten\n",
    "    cnn = base.output\n",
    "    cnn = AveragePooling2D(pool_size = (2, 2))(cnn)\n",
    "    cnn = Flatten()(cnn)\n",
    "    cnn = Dense(256)(cnn)\n",
    "    cnn = Dropout(0.5)(cnn)\n",
    "    cnn = Dense(len(LABELS), activation = 'softmax')(cnn)\n",
    "\n",
    "    cnn = Model(inputs = base.input, outputs = cnn, name = model_name)\n",
    "    \n",
    "    try:\n",
    "        # Try loading the already-made model\n",
    "        cnn.load_weights('models/%s.h5' % model_name)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    cnn.compile(loss = keras.losses.categorical_crossentropy, optimizer = keras.optimizers.Adam(learning_rate=0.01, beta_1 = 0.9, beta_2 = 0.9), metrics=['accuracy'])\n",
    "\n",
    "    cnn.summary()\n",
    "\n",
    "    # history = cnn.fit(X, y, epochs=epochs, verbose=True, validation_data=(test_X, test_y), callbacks = [ EarlyStopping() ])\n",
    "    history = cnn.fit_generator(train_flow,\n",
    "                                validation_data = test_flow,\n",
    "                                epochs=epochs,\n",
    "                                verbose=True,\n",
    "                                callbacks = [\n",
    "                                    ModelCheckpoint('models/%s.h5' % model_name, monitor = 'val_loss', verbose = False, save_best_only = True, save_weights_only = False, mode='auto', period = 1),\n",
    "                                    ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 5, verbose = True, mode='auto', cooldown = 0, min_lr = 0.000001)\n",
    "                                ])\n",
    "    cnn.save_weights('models/%s.h5' % model_name)\n",
    "\n",
    "    accuracy = cnn.evaluate(test_X, test_y)[1]\n",
    "    \n",
    "    if submission_data is not None:\n",
    "        submission_X = []\n",
    "        for i, submission_row in submission_data.iterrows():\n",
    "            submission_X.append(submission_row['data'])\n",
    "        submission_X = np.array(submission_X)\n",
    "        submission_X = submission_X.reshape(submission_X.shape[0], row_len, col_len)\n",
    "        submission_X = np.repeat(submission_X[..., np.newaxis], 3, -1)\n",
    "        \n",
    "        submission_rows = cnn.predict(submission_X)\n",
    "        \n",
    "        submission = []\n",
    "        for i, submission_row in submission_data.iterrows():\n",
    "            label = np.argmax(submission_rows[i])\n",
    "            submission.append({ \"Id\": i, \"label\": decode_label(label) })\n",
    "            \n",
    "        pd.DataFrame(submission).to_csv('submission.csv', index = False)\n",
    "        \n",
    "\n",
    "    return accuracy, history\n",
    "    \n",
    "\n",
    "if SETTINGS[\"CLASSIFY_METHOD_C\"]:\n",
    "    \n",
    "    # Preprocess the data and shuffle\n",
    "    train_data = get_df(METHOD_A_DIRECTORY, \"train\").sample(frac=1).reset_index(drop = True)\n",
    "    submission_data = get_df(METHOD_A_DIRECTORY, \"test\")\n",
    "\n",
    "    # Test: uniformly distribute all classes\n",
    "    # train_data = train_data.sample(frac=1).reset_index(drop = True)\n",
    "    # train_count = train_data[train_data['label'] == 'covid'].shape[0] - 10\n",
    "    # train_temp = pd.concat([\n",
    "    #     train_data[train_data['label'] == 'normal'].iloc[0:train_count],\n",
    "    #     train_data[train_data['label'] == 'viral'].iloc[0:train_count],\n",
    "    #     train_data[train_data['label'] == 'bacterial'].iloc[0:train_count],\n",
    "    #     train_data[train_data['label'] == 'covid'].iloc[0:train_count]\n",
    "    # ])\n",
    "    # train_index = train_temp.index.tolist()\n",
    "    # test_temp = train_data.drop(train_index).sample(frac=1).reset_index(drop = True)\n",
    "    # train_temp = train_temp.sample(frac=1).reset_index(drop = True)\n",
    "    # End Test\n",
    "    \n",
    "    percent_train = .8\n",
    "    train_temp = train_data.iloc[0:int(train_data.shape[0] * percent_train)]\n",
    "    test_temp = train_data.iloc[int(train_data.shape[0] * percent_train):]\n",
    "\n",
    "    accuracy, history = classifier_cnn(train_temp, test_temp, 200, batch_size = 32, submission_data = submission_data, model_name = 'pre-trained_cnn')\n",
    "    \n",
    "    print(accuracy)\n",
    "\n",
    "    history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WeM9024rxZ5P"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8c718762d283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4wyE7v-fccSM"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "import keras\n",
    "from keras import utils\n",
    "from keras.engine.input_layer import Input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Add, SeparableConv2D, Conv2D, ZeroPadding2D, MaxPooling2D, AveragePooling2D, Dropout, Dense, Flatten, LeakyReLU, Activation, BatchNormalization, UpSampling2D\n",
    "\n",
    "##\n",
    "#   CORONet Shortcuts\n",
    "##\n",
    "\n",
    "mid_layer_activation = 'relu' # 0-to-1 activation\n",
    "relu_leak = 0.3\n",
    "\n",
    "# Creates a set of three convolutions that act as a bottleneck. Speeds up learning.\n",
    "# source: https://www.kaggle.com/akumaldo/resnet-from-scratch-keras\n",
    "def Bottleneck(center_kernel_size, conv_filters):\n",
    "\n",
    "    # Conform to Keras layer spec\n",
    "    def bottleneck(cnn):\n",
    "\n",
    "        cnn_shortcut = cnn\n",
    "\n",
    "        # Bottleneck convolutions\n",
    "        for i, kernel_size in enumerate([ (1, 1), (center_kernel_size, center_kernel_size), (1, 1) ]):\n",
    "            cnn = Conv2D(conv_filters[i], kernel_size = kernel_size, strides = (1, 1), padding = 'same')(cnn)\n",
    "            cnn = BatchNormalization(axis = 3)(cnn)\n",
    "            cnn = LeakyReLU(alpha = relu_leak)(cnn)\n",
    "\n",
    "        # Add shortcut\n",
    "        cnn = Add()([ cnn, cnn_shortcut ])\n",
    "        cnn = LeakyReLU(alpha = relu_leak)(cnn)\n",
    "\n",
    "        return cnn\n",
    "\n",
    "    return bottleneck\n",
    "\n",
    "def ConvBlock(comp_kernel_size, conv_filters, stride):\n",
    "\n",
    "    # Conform to Keras layer spec\n",
    "    def conv_block(cnn):\n",
    "        cnn_shortcut = cnn\n",
    "\n",
    "        # Entry convolution\n",
    "        cnn = Conv2D(conv_filters[0], kernel_size = (1, 1), strides = (stride, stride), padding = 'same')(cnn)\n",
    "        cnn = BatchNormalization(axis = 3)(cnn)\n",
    "        cnn = LeakyReLU(alpha = relu_leak)(cnn)\n",
    "\n",
    "        # Computational convolution\n",
    "        cnn = Conv2D(conv_filters[1], kernel_size = (comp_kernel_size, comp_kernel_size), strides = (1, 1), padding = 'same')(cnn)\n",
    "        cnn = BatchNormalization(axis = 3)(cnn)\n",
    "        cnn = LeakyReLU(alpha = relu_leak)(cnn)\n",
    "\n",
    "        # Close bottle w/o activation\n",
    "        cnn = Conv2D(conv_filters[2], kernel_size = (1, 1), strides = (1, 1), padding = 'same')(cnn)\n",
    "        cnn = BatchNormalization(axis = 3)(cnn)\n",
    "\n",
    "        # Repeat for shortcut path\n",
    "        cnn_shortcut = Conv2D(conv_filters[2], kernel_size = (1, 1), strides = (stride, stride), padding = 'same')(cnn_shortcut)\n",
    "        cnn_shortcut = BatchNormalization(axis = 3)(cnn_shortcut)\n",
    "\n",
    "        # Add shortcut\n",
    "        cnn = Add()([ cnn, cnn_shortcut ])\n",
    "        cnn = LeakyReLU(alpha = relu_leak)(cnn)\n",
    "\n",
    "        return cnn\n",
    "\n",
    "    return conv_block\n",
    "\n",
    "\n",
    "def classifier_cnn(train_data, test_data, epochs = 15, batch_size = 64, submission_data = None, model_name = 'cnn'):\n",
    "\n",
    "    # since classes are strings, we need a way to represent them numerically for the NN\n",
    "    encode_label = lambda label: LABELS.index(label)\n",
    "    decode_label = lambda index: LABELS[int(index)]\n",
    "    \n",
    "    # Store TRAINING data and labels\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, train_row in train_data.iterrows():\n",
    "        X.append(train_row['data'])\n",
    "        y.append(encode_label(train_row['label']))\n",
    "    \n",
    "    # Next, store TESTING data and lables\n",
    "    test_X = []\n",
    "    test_y = []\n",
    "    \n",
    "    for i, test_row in test_data.iterrows():\n",
    "        test_X.append(test_row['data'])\n",
    "        test_y.append(encode_label(test_row['label']))\n",
    "\n",
    "    # Store class weights\n",
    "    class_weights = class_weight.compute_class_weight('balanced', [ 0, 1, 2, 3 ], y)\n",
    "\n",
    "    # Store data dimensions for later use\n",
    "    row_len = len(X[0])\n",
    "    col_len = len(X[0][0])\n",
    "    train_data_len = len(X)\n",
    "    input_shape = (row_len, col_len, 1)\n",
    "    \n",
    "    # Create numerical labels from the categorical classes\n",
    "    y = utils.to_categorical(y, len(LABELS))\n",
    "    test_y = utils.to_categorical(test_y, len(LABELS))\n",
    "    \n",
    "    # Reshape training and testing features (add 2 extra channels to features for ResNet)\n",
    "    X = np.array(X)\n",
    "    X = X.reshape(X.shape[0], row_len, col_len, 1)\n",
    "    test_X = np.array(test_X)\n",
    "    test_X = test_X.reshape(test_X.shape[0], row_len, col_len, 1)\n",
    "\n",
    "    # Create image generators\n",
    "    train_gen = ImageDataGenerator(\n",
    "        rotation_range = 5,\n",
    "        width_shift_range = 0.1,\n",
    "        height_shift_range = 0.1,\n",
    "        shear_range = 0.1,\n",
    "        zoom_range = 0.1,\n",
    "        horizontal_flip = True\n",
    "    )\n",
    "    test_gen = ImageDataGenerator(\n",
    "        rotation_range = 5,\n",
    "        width_shift_range = 0.1,\n",
    "        height_shift_range = 0.1,\n",
    "        shear_range = 0.1,\n",
    "        zoom_range = 0.1,\n",
    "        horizontal_flip = True\n",
    "    )\n",
    "\n",
    "    train_gen.fit(X, augment = True, seed = 1, rounds = 1)\n",
    "    test_gen.fit(test_X, augment = True, seed = 1, rounds = 1)\n",
    "\n",
    "    train_flow = train_gen.flow(X, y, batch_size = batch_size, seed = 1, shuffle = True)\n",
    "    test_flow = test_gen.flow(test_X, test_y, batch_size = batch_size, seed = 1, shuffle = True)\n",
    "\n",
    "    try:\n",
    "        # Try loading the already-made model\n",
    "        cnn = load_model('models/%s.h5' % model_name)\n",
    "    except:\n",
    "\n",
    "        ##\n",
    "        #   CORONet Layers\n",
    "        ##\n",
    "\n",
    "        inputs = Input(input_shape)\n",
    "\n",
    "        # If we can't load it, we'll make a new one\n",
    "        cnn = ZeroPadding2D((3, 3))(inputs)\n",
    "\n",
    "        ##\n",
    "        #   Layer Group 1\n",
    "        ##\n",
    "        \n",
    "        cnn = Conv2D(32, kernel_size = (9, 9), strides = (1, 1), padding = 'same')(cnn)\n",
    "        cnn = BatchNormalization()(cnn)\n",
    "        cnn = LeakyReLU(alpha = relu_leak)(cnn)\n",
    "        cnn = MaxPooling2D((3, 3))(cnn)\n",
    "\n",
    "        ##\n",
    "        #   Layer Group 2\n",
    "        ##\n",
    "\n",
    "        filters = [ 32, 32, 128 ]\n",
    "        cnn = ConvBlock(3, filters, 1)(cnn)\n",
    "        cnn = Bottleneck(3, filters)(cnn)\n",
    "        cnn = Bottleneck(3, filters)(cnn)\n",
    "    \n",
    "        ##\n",
    "        #   Layer Group 3\n",
    "        ##\n",
    "\n",
    "        filters = [ 64, 64, 256 ]\n",
    "        cnn = ConvBlock(3, filters, 2)(cnn)\n",
    "        cnn = Bottleneck(3, filters)(cnn)\n",
    "        cnn = Bottleneck(3, filters)(cnn)\n",
    "    \n",
    "        ##\n",
    "        #   Layer Group 4\n",
    "        ##\n",
    "\n",
    "        filters = [ 128, 128, 512 ]\n",
    "        cnn = ConvBlock(3, filters, 2)(cnn)\n",
    "        cnn = Bottleneck(3, filters)(cnn)\n",
    "        cnn = Bottleneck(3, filters)(cnn)\n",
    "        cnn = Bottleneck(3, filters)(cnn)\n",
    "        cnn = Bottleneck(3, filters)(cnn)\n",
    "        cnn = Bottleneck(3, filters)(cnn)\n",
    "    \n",
    "        ##\n",
    "        #   Layer Group 5\n",
    "        ##\n",
    "\n",
    "        filters = [ 256, 256, 1024 ]\n",
    "        cnn = ConvBlock(3, filters, 2)(cnn)\n",
    "        cnn = Bottleneck(3, filters)(cnn)\n",
    "        cnn = Bottleneck(3, filters)(cnn)\n",
    "\n",
    "        ##\n",
    "        #   Output Layer Group\n",
    "        ##\n",
    "\n",
    "        # Pool and flatten\n",
    "        cnn = AveragePooling2D(pool_size = (2, 2))(cnn)\n",
    "        cnn = Flatten()(cnn)\n",
    "        cnn = Dense(1024)(cnn)\n",
    "        cnn = LeakyReLU(alpha = relu_leak)(cnn)\n",
    "\n",
    "        # Drop 50% of connections\n",
    "        cnn = Dropout(0.5)(cnn)\n",
    "\n",
    "        cnn = Dense(len(LABELS), activation = 'softmax')(cnn)\n",
    "\n",
    "        cnn = Model(inputs = inputs, outputs = cnn, name = model_name)\n",
    "\n",
    "        cnn.compile(loss = keras.losses.categorical_crossentropy, optimizer = keras.optimizers.Adam(learning_rate=0.01, beta_1 = 0.9, beta_2 = 0.9), metrics=['accuracy'])\n",
    "\n",
    "    cnn.summary()\n",
    "\n",
    "    # history = cnn.fit(X, y, epochs=epochs, verbose=True, validation_data=(test_X, test_y), callbacks = [ EarlyStopping() ])\n",
    "    history = cnn.fit_generator(train_flow,\n",
    "                                validation_data = test_flow,\n",
    "                                epochs=epochs,\n",
    "                                verbose=True,\n",
    "                                callbacks = [\n",
    "                                    ModelCheckpoint('models/%s.h5' % model_name, monitor = 'val_loss', verbose = True, save_best_only = True, save_weights_only = True, mode='min'),\n",
    "                                    ReduceLROnPlateau(monitor = 'val_loss', patience = 3, verbose = True, mode='min', min_lr = 0.000001)\n",
    "                                ],\n",
    "                                class_weight = class_weights)\n",
    "    cnn.save('models/%s.h5' % model_name)\n",
    "\n",
    "    accuracy = cnn.evaluate(test_X, test_y)[1]\n",
    "    \n",
    "    if submission_data is not None:\n",
    "        submission_X = []\n",
    "        for i, submission_row in submission_data.iterrows():\n",
    "            submission_X.append(submission_row['data'])\n",
    "        submission_X = np.array(submission_X)\n",
    "        submission_X = submission_X.reshape(submission_X.shape[0], row_len, col_len, 1)\n",
    "        \n",
    "        submission_rows = cnn.predict(submission_X)\n",
    "        \n",
    "        submission = []\n",
    "        for i, submission_row in submission_data.iterrows():\n",
    "            label = np.argmax(submission_rows[i])\n",
    "            submission.append({ \"Id\": i, \"label\": decode_label(label) })\n",
    "            \n",
    "        pd.DataFrame(submission).to_csv('submission.csv', index = False)\n",
    "        \n",
    "\n",
    "    return accuracy, history\n",
    "    \n",
    "\n",
    "if SETTINGS[\"CLASSIFY_METHOD_C\"]:\n",
    "    \n",
    "    # Preprocess the data and shuffle\n",
    "    train_data = get_df(METHOD_A_DIRECTORY, \"train\").sample(frac=1).reset_index(drop = True)\n",
    "    submission_data = get_df(METHOD_A_DIRECTORY, \"test\")\n",
    "\n",
    "    # Test: uniformly distribute all classes\n",
    "    train_data = train_data.sample(frac=1).reset_index(drop = True)\n",
    "    train_count = train_data[train_data['label'] == 'covid'].shape[0] - 30\n",
    "    train_temp = pd.concat([\n",
    "        train_data[train_data['label'] == 'normal'].iloc[0:train_count],\n",
    "        train_data[train_data['label'] == 'viral'].iloc[0:train_count],\n",
    "        train_data[train_data['label'] == 'bacterial'].iloc[0:train_count],\n",
    "        train_data[train_data['label'] == 'covid'].iloc[0:train_count]\n",
    "    ])\n",
    "    train_index = train_temp.index.tolist()\n",
    "    test_temp = train_data.drop(train_index).sample(frac=1).reset_index(drop = True)\n",
    "    train_temp = train_temp.sample(frac=1).reset_index(drop = True)\n",
    "    # End Test\n",
    "    \n",
    "    # percent_train = .8\n",
    "    # train_temp = train_data.iloc[0:int(train_data.shape[0] * percent_train)]\n",
    "    # test_temp = train_data.iloc[int(train_data.shape[0] * percent_train):]\n",
    "\n",
    "    accuracy, history = classifier_cnn(train_temp, test_temp, 50, batch_size = 32, submission_data = submission_data)\n",
    "    \n",
    "    print(accuracy)\n",
    "\n",
    "    history"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda8437816452674dce9c553dcca074e7d9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0672538686ae4cf0a2de1d698e86c65f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06cfc1935baf44709af70396b0e65989": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Method C on train data:  11%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e6c5462869947bfa40a0b1330c91705",
      "max": 1127,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5978493a64214f4b84b7455c15241012",
      "value": 127
     }
    },
    "1621e167f9f14c5b9963c0950e70a9b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5fe89707f2a649b89a86e88af49aee8b",
      "placeholder": "​",
      "style": "IPY_MODEL_3b17d96139d04f07923cf181c2f3c962",
      "value": " 126/1127 [01:26&lt;10:57,  1.52it/s]"
     }
    },
    "2429ec87a6b04ce79acee1a2d1c0fedb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_06cfc1935baf44709af70396b0e65989",
       "IPY_MODEL_1621e167f9f14c5b9963c0950e70a9b3"
      ],
      "layout": "IPY_MODEL_84aca0dba76e490f80d05a78b1f85df8"
     }
    },
    "33157261d8904ba2a738f5f3db6e7ab8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_85e8552356a14da8a1d51ccdce6b966f",
       "IPY_MODEL_6f556035b5b541c09ce47e7c896b5088"
      ],
      "layout": "IPY_MODEL_50df7cb2f9954d149c541e7e46c6a018"
     }
    },
    "37913a7857b544d19e3ee8618e0194a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc9d64d7c55942cdb1b47b79daafcbd1",
      "placeholder": "​",
      "style": "IPY_MODEL_69fb7085f0e040909dba1ab4349b323a",
      "value": " 484/484 [13:53&lt;00:00,  1.72s/it]"
     }
    },
    "3831024e35bf423cb091b1693d71144f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3964aeaa8a544157a3dd2c259e833a01": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b17d96139d04f07923cf181c2f3c962": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b27e4e9df86493d8a08d634cd4485e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4de47902a1f94cd79e476c7722a32cc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65a9dba714f64c81bf6e3ecb12343fc8",
      "placeholder": "​",
      "style": "IPY_MODEL_81262396b68140a3b681e19f981c9828",
      "value": " 1127/1127 [26:14&lt;00:00,  1.40s/it]"
     }
    },
    "4e6c5462869947bfa40a0b1330c91705": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50df7cb2f9954d149c541e7e46c6a018": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51b32880599b4c648aa69235c1c447eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3964aeaa8a544157a3dd2c259e833a01",
      "placeholder": "​",
      "style": "IPY_MODEL_fbf018a0c07d44de9227ce02d25eb748",
      "value": " 484/484 [04:45&lt;00:00,  1.70it/s]"
     }
    },
    "51c0894a22ff4ed892229ab7507b249f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58df504c932549c990c3323e067d9c81": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f1c4168f39634312b2075e0562d80c7c",
       "IPY_MODEL_37913a7857b544d19e3ee8618e0194a7"
      ],
      "layout": "IPY_MODEL_f918089279f645618d3b9b21ac01f8db"
     }
    },
    "5978493a64214f4b84b7455c15241012": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5e2fec75767b430984ec2fc193b3ee91": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5fe89707f2a649b89a86e88af49aee8b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65a2503bb593495780a512bbe2d6b45b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65a9dba714f64c81bf6e3ecb12343fc8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69fb7085f0e040909dba1ab4349b323a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6bf38f1c96a84d48813aacaef6239af8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_afa2d93f97a6478dabd4fbdbacba2777",
       "IPY_MODEL_a571fa2a204c4f9fae4be93b434e8e5e"
      ],
      "layout": "IPY_MODEL_c11768d0e07b424786c45d22f54e5fcf"
     }
    },
    "6e8b6652439e4379a783931539e16e12": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Method A on test data: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51c0894a22ff4ed892229ab7507b249f",
      "max": 484,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c4ec4b16d30c42fb91d37bc824d4047c",
      "value": 484
     }
    },
    "6eb6c738b43f4c5cba142c4ca555df14": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Method A on train data: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de315c4e32854acf875f204e5f142f16",
      "max": 1127,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd7c589e40584cdbb369082ed41fbd7f",
      "value": 1127
     }
    },
    "6f556035b5b541c09ce47e7c896b5088": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c963475afdc4e5592c90a513cf35172",
      "placeholder": "​",
      "style": "IPY_MODEL_4b27e4e9df86493d8a08d634cd4485e5",
      "value": " 1127/1127 [10:48&lt;00:00,  1.74it/s]"
     }
    },
    "725586f794a24e5e8ba5e564021d998b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7b91d23b597f4a7c9ecdd665a8f36337": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c963475afdc4e5592c90a513cf35172": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e25455b9492426f9dd6a3186436c6c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81262396b68140a3b681e19f981c9828": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84aca0dba76e490f80d05a78b1f85df8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85e8552356a14da8a1d51ccdce6b966f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Method B on train data: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3831024e35bf423cb091b1693d71144f",
      "max": 1127,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd299e21f41c4688bbde1379511f88f8",
      "value": 1127
     }
    },
    "911825bc23da4dc49f35455738046005": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93a5c8e1fd6e48e4842a3ff889d1563e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_edc70c03a07a402aa75f4a0faabee760",
       "IPY_MODEL_f4985a3e43c440febcd0c2e887be9d06"
      ],
      "layout": "IPY_MODEL_d0e4fda1c8334a2a80c5ab54d966cc58"
     }
    },
    "9ee5508d2e214ad083d08bb038e984f6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1a3e17521e14fb1997ad4b67afb57ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a4260eaa1fcb414ea1cb2c6e75ebb8e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6eb6c738b43f4c5cba142c4ca555df14",
       "IPY_MODEL_4de47902a1f94cd79e476c7722a32cc7"
      ],
      "layout": "IPY_MODEL_b4c0508a55f34327a1b78e04fd0ffcdd"
     }
    },
    "a571fa2a204c4f9fae4be93b434e8e5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9eb9820e7cd4d64b77238171f8229d2",
      "placeholder": "​",
      "style": "IPY_MODEL_65a2503bb593495780a512bbe2d6b45b",
      "value": " 484/? [00:04&lt;00:00, 98.99it/s]"
     }
    },
    "afa2d93f97a6478dabd4fbdbacba2777": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Storing test rows for pre-processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0672538686ae4cf0a2de1d698e86c65f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_725586f794a24e5e8ba5e564021d998b",
      "value": 1
     }
    },
    "b4c0508a55f34327a1b78e04fd0ffcdd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c11768d0e07b424786c45d22f54e5fcf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4ec4b16d30c42fb91d37bc824d4047c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c9eb9820e7cd4d64b77238171f8229d2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd299e21f41c4688bbde1379511f88f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cd7c589e40584cdbb369082ed41fbd7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d0e4fda1c8334a2a80c5ab54d966cc58": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de315c4e32854acf875f204e5f142f16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6ed0a311137403dba43b46b8625a323": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e8b6652439e4379a783931539e16e12",
       "IPY_MODEL_51b32880599b4c648aa69235c1c447eb"
      ],
      "layout": "IPY_MODEL_911825bc23da4dc49f35455738046005"
     }
    },
    "edc70c03a07a402aa75f4a0faabee760": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Storing train rows for preprocessing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ee5508d2e214ad083d08bb038e984f6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5e2fec75767b430984ec2fc193b3ee91",
      "value": 1
     }
    },
    "f1c4168f39634312b2075e0562d80c7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Method A on test data: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b91d23b597f4a7c9ecdd665a8f36337",
      "max": 484,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a1a3e17521e14fb1997ad4b67afb57ee",
      "value": 484
     }
    },
    "f4985a3e43c440febcd0c2e887be9d06": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff49719ad32d4d7fb1c609b994c10cad",
      "placeholder": "​",
      "style": "IPY_MODEL_7e25455b9492426f9dd6a3186436c6c3",
      "value": " 1127/? [00:11&lt;00:00, 95.30it/s]"
     }
    },
    "f918089279f645618d3b9b21ac01f8db": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbf018a0c07d44de9227ce02d25eb748": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc9d64d7c55942cdb1b47b79daafcbd1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff49719ad32d4d7fb1c609b994c10cad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
